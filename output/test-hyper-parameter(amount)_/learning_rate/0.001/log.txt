K=8, L=1, SE_file='./data/train_data/transaction_amount/SE_data/group0/SE.txt', batch_size=16, d=8, decay_epoch=10, device='cpu', learning_rate=0.001, log_file='./output/test-hyper-parameter(amount)_/learning_rate/0.001/log.txt', max_epoch=50, model_file='./output/test-hyper-parameter(amount)_/learning_rate/0.001/model.pkl', num_his=3, num_pred=1, output_folder='./output/test-hyper-parameter(amount)_/learning_rate/0.001', patience=100, test_ratio=0.1, time_slot=1440, traffic_file='./data/train_data/transaction_amount/train_data/count_group0_dist3000.h5', train_ratio=0.8, val_ratio=0.1, view_batch_freq=100
main output folder./output/test-hyper-parameter(amount)_/learning_rate/0.001
loading data...
trainX: torch.Size([91, 3, 5])		 trainY: torch.Size([91, 1, 5])
valX:   torch.Size([8, 3, 5])		valY:   torch.Size([8, 1, 5])
testX:   torch.Size([9, 3, 5])		testY:   torch.Size([9, 1, 5])
data loaded!
compiling model...
trainable parameters: 209,923
**** training model ****
2022-09-26 19:53:40 | epoch: 0001/50, training time: 0.6s, inference time: 0.0s
train loss: 1119.8661, val_loss: 460.4884
val loss decrease from inf to 460.4884, saving model to ./output/test-hyper-parameter(amount)_/learning_rate/0.001/model.pkl
2022-09-26 19:53:40 | epoch: 0002/50, training time: 0.5s, inference time: 0.0s
train loss: 367.1112, val_loss: 462.1259
2022-09-26 19:53:41 | epoch: 0003/50, training time: 0.6s, inference time: 0.0s
train loss: 454.8736, val_loss: 455.6772
val loss decrease from 460.4884 to 455.6772, saving model to ./output/test-hyper-parameter(amount)_/learning_rate/0.001/model.pkl
2022-09-26 19:53:42 | epoch: 0004/50, training time: 0.6s, inference time: 0.0s
train loss: 326.4670, val_loss: 458.1403
2022-09-26 19:53:42 | epoch: 0005/50, training time: 0.6s, inference time: 0.0s
train loss: 404.3751, val_loss: 453.8932
val loss decrease from 455.6772 to 453.8932, saving model to ./output/test-hyper-parameter(amount)_/learning_rate/0.001/model.pkl
2022-09-26 19:53:43 | epoch: 0006/50, training time: 0.7s, inference time: 0.0s
train loss: 235.7038, val_loss: 432.5420
val loss decrease from 453.8932 to 432.5420, saving model to ./output/test-hyper-parameter(amount)_/learning_rate/0.001/model.pkl
2022-09-26 19:53:44 | epoch: 0007/50, training time: 0.8s, inference time: 0.0s
train loss: 261.7978, val_loss: 438.6075
2022-09-26 19:53:44 | epoch: 0008/50, training time: 0.7s, inference time: 0.0s
train loss: 237.8602, val_loss: 455.2988
2022-09-26 19:53:45 | epoch: 0009/50, training time: 0.8s, inference time: 0.0s
train loss: 260.3068, val_loss: 422.3373
val loss decrease from 432.5420 to 422.3373, saving model to ./output/test-hyper-parameter(amount)_/learning_rate/0.001/model.pkl
2022-09-26 19:53:46 | epoch: 0010/50, training time: 0.7s, inference time: 0.0s
train loss: 227.9018, val_loss: 413.5034
val loss decrease from 422.3373 to 413.5034, saving model to ./output/test-hyper-parameter(amount)_/learning_rate/0.001/model.pkl
2022-09-26 19:53:47 | epoch: 0011/50, training time: 0.7s, inference time: 0.0s
train loss: 354.3019, val_loss: 429.8086
2022-09-26 19:53:47 | epoch: 0012/50, training time: 0.7s, inference time: 0.0s
train loss: 375.6523, val_loss: 427.4988
2022-09-26 19:53:48 | epoch: 0013/50, training time: 0.7s, inference time: 0.0s
train loss: 191.4856, val_loss: 423.8231
2022-09-26 19:53:49 | epoch: 0014/50, training time: 0.7s, inference time: 0.0s
train loss: 334.1917, val_loss: 402.0228
val loss decrease from 413.5034 to 402.0228, saving model to ./output/test-hyper-parameter(amount)_/learning_rate/0.001/model.pkl
2022-09-26 19:53:50 | epoch: 0015/50, training time: 0.7s, inference time: 0.0s
train loss: 290.1792, val_loss: 397.7385
val loss decrease from 402.0228 to 397.7385, saving model to ./output/test-hyper-parameter(amount)_/learning_rate/0.001/model.pkl
2022-09-26 19:53:50 | epoch: 0016/50, training time: 0.7s, inference time: 0.0s
train loss: 189.0910, val_loss: 405.1294
2022-09-26 19:53:51 | epoch: 0017/50, training time: 0.7s, inference time: 0.0s
train loss: 143.8292, val_loss: 410.5294
2022-09-26 19:53:52 | epoch: 0018/50, training time: 0.7s, inference time: 0.0s
train loss: 228.9085, val_loss: 390.3279
val loss decrease from 397.7385 to 390.3279, saving model to ./output/test-hyper-parameter(amount)_/learning_rate/0.001/model.pkl
2022-09-26 19:53:53 | epoch: 0019/50, training time: 0.7s, inference time: 0.0s
train loss: 228.4989, val_loss: 408.6152
2022-09-26 19:53:53 | epoch: 0020/50, training time: 0.7s, inference time: 0.0s
train loss: 236.7451, val_loss: 446.1903
2022-09-26 19:53:54 | epoch: 0021/50, training time: 0.7s, inference time: 0.0s
train loss: 211.8830, val_loss: 424.9430
2022-09-26 19:53:55 | epoch: 0022/50, training time: 0.7s, inference time: 0.0s
train loss: 263.3856, val_loss: 393.3439
2022-09-26 19:53:56 | epoch: 0023/50, training time: 0.8s, inference time: 0.0s
train loss: 194.8129, val_loss: 353.7127
val loss decrease from 390.3279 to 353.7127, saving model to ./output/test-hyper-parameter(amount)_/learning_rate/0.001/model.pkl
2022-09-26 19:53:56 | epoch: 0024/50, training time: 0.7s, inference time: 0.0s
train loss: 218.5421, val_loss: 373.7049
2022-09-26 19:53:57 | epoch: 0025/50, training time: 0.7s, inference time: 0.0s
train loss: 195.9964, val_loss: 384.2269
2022-09-26 19:53:58 | epoch: 0026/50, training time: 0.7s, inference time: 0.0s
train loss: 215.4959, val_loss: 415.7167
2022-09-26 19:53:59 | epoch: 0027/50, training time: 0.7s, inference time: 0.0s
train loss: 190.7080, val_loss: 406.9639
2022-09-26 19:53:59 | epoch: 0028/50, training time: 0.7s, inference time: 0.0s
train loss: 147.7846, val_loss: 364.7231
2022-09-26 19:54:00 | epoch: 0029/50, training time: 0.7s, inference time: 0.0s
train loss: 127.8551, val_loss: 338.1970
val loss decrease from 353.7127 to 338.1970, saving model to ./output/test-hyper-parameter(amount)_/learning_rate/0.001/model.pkl
2022-09-26 19:54:01 | epoch: 0030/50, training time: 0.8s, inference time: 0.0s
train loss: 118.0584, val_loss: 339.2535
2022-09-26 19:54:02 | epoch: 0031/50, training time: 0.8s, inference time: 0.0s
train loss: 145.1206, val_loss: 338.0104
val loss decrease from 338.1970 to 338.0104, saving model to ./output/test-hyper-parameter(amount)_/learning_rate/0.001/model.pkl
2022-09-26 19:54:02 | epoch: 0032/50, training time: 0.8s, inference time: 0.0s
train loss: 81.3897, val_loss: 333.7553
val loss decrease from 338.0104 to 333.7553, saving model to ./output/test-hyper-parameter(amount)_/learning_rate/0.001/model.pkl
2022-09-26 19:54:03 | epoch: 0033/50, training time: 0.7s, inference time: 0.0s
train loss: 199.9888, val_loss: 348.5543
2022-09-26 19:54:04 | epoch: 0034/50, training time: 0.7s, inference time: 0.0s
train loss: 83.2183, val_loss: 362.0358
2022-09-26 19:54:05 | epoch: 0035/50, training time: 0.7s, inference time: 0.0s
train loss: 130.4753, val_loss: 355.6785
2022-09-26 19:54:05 | epoch: 0036/50, training time: 0.7s, inference time: 0.0s
train loss: 103.7983, val_loss: 317.2060
val loss decrease from 333.7553 to 317.2060, saving model to ./output/test-hyper-parameter(amount)_/learning_rate/0.001/model.pkl
2022-09-26 19:54:06 | epoch: 0037/50, training time: 0.7s, inference time: 0.0s
train loss: 151.6626, val_loss: 292.3024
val loss decrease from 317.2060 to 292.3024, saving model to ./output/test-hyper-parameter(amount)_/learning_rate/0.001/model.pkl
2022-09-26 19:54:07 | epoch: 0038/50, training time: 0.7s, inference time: 0.0s
train loss: 96.4413, val_loss: 286.9148
val loss decrease from 292.3024 to 286.9148, saving model to ./output/test-hyper-parameter(amount)_/learning_rate/0.001/model.pkl
2022-09-26 19:54:08 | epoch: 0039/50, training time: 0.7s, inference time: 0.0s
train loss: 144.1367, val_loss: 326.2091
2022-09-26 19:54:08 | epoch: 0040/50, training time: 0.7s, inference time: 0.0s
train loss: 106.4629, val_loss: 326.1456
2022-09-26 19:54:09 | epoch: 0041/50, training time: 0.7s, inference time: 0.0s
train loss: 65.0765, val_loss: 308.3483
2022-09-26 19:54:10 | epoch: 0042/50, training time: 0.8s, inference time: 0.0s
train loss: 111.9902, val_loss: 290.7119
2022-09-26 19:54:11 | epoch: 0043/50, training time: 0.7s, inference time: 0.0s
train loss: 226.2312, val_loss: 277.7830
val loss decrease from 286.9148 to 277.7830, saving model to ./output/test-hyper-parameter(amount)_/learning_rate/0.001/model.pkl
2022-09-26 19:54:11 | epoch: 0044/50, training time: 0.7s, inference time: 0.0s
train loss: 96.0265, val_loss: 295.8333
2022-09-26 19:54:12 | epoch: 0045/50, training time: 0.7s, inference time: 0.0s
train loss: 109.7268, val_loss: 311.4308
2022-09-26 19:54:13 | epoch: 0046/50, training time: 0.7s, inference time: 0.0s
train loss: 179.4887, val_loss: 313.5807
2022-09-26 19:54:14 | epoch: 0047/50, training time: 0.7s, inference time: 0.0s
train loss: 282.3208, val_loss: 324.9756
2022-09-26 19:54:14 | epoch: 0048/50, training time: 0.7s, inference time: 0.0s
train loss: 164.7689, val_loss: 333.1143
2022-09-26 19:54:15 | epoch: 0049/50, training time: 0.7s, inference time: 0.0s
train loss: 51.8719, val_loss: 317.3881
2022-09-26 19:54:16 | epoch: 0050/50, training time: 0.7s, inference time: 0.0s
train loss: 201.4090, val_loss: 315.7590
Training and validation are completed, and model has been stored as ./output/test-hyper-parameter(amount)_/learning_rate/0.001/model.pkl
**** testing model ****
loading model from ./output/test-hyper-parameter(amount)_/learning_rate/0.001/model.pkl
model restored!
evaluating...
testing time: 0.0s
                MAE		RMSE		MAPE
train            5.57		7.69		13.29%
val              14.05		17.77		31.81%
test             12.14		14.69		34.73%
performance in each prediction step
step: 01         12.14		14.69		34.73%
average:         12.14		14.69		34.73%
total time: 0.6min
