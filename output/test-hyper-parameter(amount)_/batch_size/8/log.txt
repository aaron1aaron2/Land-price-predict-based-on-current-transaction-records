K=8, L=1, SE_file='./data/train_data/transaction_amount/SE_data/group0/SE.txt', batch_size=8, d=8, decay_epoch=10, device='cpu', learning_rate=0.001, log_file='./output/test-hyper-parameter(amount)_/batch_size/8/log.txt', max_epoch=50, model_file='./output/test-hyper-parameter(amount)_/batch_size/8/model.pkl', num_his=3, num_pred=1, output_folder='./output/test-hyper-parameter(amount)_/batch_size/8/', patience=100, test_ratio=0.1, time_slot=1440, traffic_file='./data/train_data/transaction_amount/train_data/count_group0_dist3000.h5', train_ratio=0.8, val_ratio=0.1, view_batch_freq=100
main output folder./output/test-hyper-parameter(amount)_/batch_size/8
loading data...
trainX: torch.Size([91, 3, 5])		 trainY: torch.Size([91, 1, 5])
valX:   torch.Size([8, 3, 5])		valY:   torch.Size([8, 1, 5])
testX:   torch.Size([9, 3, 5])		testY:   torch.Size([9, 1, 5])
data loaded!
compiling model...
trainable parameters: 209,923
**** training model ****
2022-09-26 19:51:32 | epoch: 0001/50, training time: 0.9s, inference time: 0.0s
train loss: 1187.2680, val_loss: 829.0900
val loss decrease from inf to 829.0900, saving model to ./output/test-hyper-parameter(amount)_/batch_size/8/model.pkl
2022-09-26 19:51:33 | epoch: 0002/50, training time: 1.4s, inference time: 0.0s
train loss: 602.8894, val_loss: 617.5389
val loss decrease from 829.0900 to 617.5389, saving model to ./output/test-hyper-parameter(amount)_/batch_size/8/model.pkl
2022-09-26 19:51:35 | epoch: 0003/50, training time: 1.2s, inference time: 0.0s
train loss: 679.8120, val_loss: 478.6427
val loss decrease from 617.5389 to 478.6427, saving model to ./output/test-hyper-parameter(amount)_/batch_size/8/model.pkl
2022-09-26 19:51:36 | epoch: 0004/50, training time: 1.0s, inference time: 0.0s
train loss: 525.2353, val_loss: 521.7985
2022-09-26 19:51:37 | epoch: 0005/50, training time: 1.0s, inference time: 0.0s
train loss: 511.3749, val_loss: 493.0266
2022-09-26 19:51:37 | epoch: 0006/50, training time: 0.7s, inference time: 0.0s
train loss: 463.4891, val_loss: 421.6380
val loss decrease from 478.6427 to 421.6380, saving model to ./output/test-hyper-parameter(amount)_/batch_size/8/model.pkl
2022-09-26 19:51:38 | epoch: 0007/50, training time: 0.9s, inference time: 0.0s
train loss: 484.4635, val_loss: 448.5839
2022-09-26 19:51:39 | epoch: 0008/50, training time: 0.7s, inference time: 0.0s
train loss: 445.4626, val_loss: 406.4661
val loss decrease from 421.6380 to 406.4661, saving model to ./output/test-hyper-parameter(amount)_/batch_size/8/model.pkl
2022-09-26 19:51:40 | epoch: 0009/50, training time: 0.7s, inference time: 0.0s
train loss: 452.0493, val_loss: 469.5746
2022-09-26 19:51:40 | epoch: 0010/50, training time: 0.7s, inference time: 0.0s
train loss: 522.6837, val_loss: 522.1662
2022-09-26 19:51:41 | epoch: 0011/50, training time: 0.7s, inference time: 0.0s
train loss: 451.5336, val_loss: 445.4629
2022-09-26 19:51:42 | epoch: 0012/50, training time: 0.7s, inference time: 0.0s
train loss: 357.2026, val_loss: 409.8367
2022-09-26 19:51:43 | epoch: 0013/50, training time: 0.7s, inference time: 0.0s
train loss: 337.9234, val_loss: 332.7769
val loss decrease from 406.4661 to 332.7769, saving model to ./output/test-hyper-parameter(amount)_/batch_size/8/model.pkl
2022-09-26 19:51:43 | epoch: 0014/50, training time: 0.8s, inference time: 0.0s
train loss: 326.0426, val_loss: 386.0265
2022-09-26 19:51:44 | epoch: 0015/50, training time: 0.7s, inference time: 0.0s
train loss: 261.4941, val_loss: 328.8052
val loss decrease from 332.7769 to 328.8052, saving model to ./output/test-hyper-parameter(amount)_/batch_size/8/model.pkl
2022-09-26 19:51:45 | epoch: 0016/50, training time: 0.8s, inference time: 0.0s
train loss: 522.3450, val_loss: 406.2564
2022-09-26 19:51:46 | epoch: 0017/50, training time: 0.8s, inference time: 0.0s
train loss: 436.4718, val_loss: 373.3032
2022-09-26 19:51:47 | epoch: 0018/50, training time: 0.8s, inference time: 0.0s
train loss: 449.5003, val_loss: 384.0464
2022-09-26 19:51:47 | epoch: 0019/50, training time: 0.7s, inference time: 0.0s
train loss: 347.7935, val_loss: 384.1476
2022-09-26 19:51:48 | epoch: 0020/50, training time: 0.7s, inference time: 0.0s
train loss: 418.9833, val_loss: 348.1772
2022-09-26 19:51:49 | epoch: 0021/50, training time: 0.7s, inference time: 0.0s
train loss: 380.0872, val_loss: 407.4593
2022-09-26 19:51:50 | epoch: 0022/50, training time: 0.7s, inference time: 0.0s
train loss: 325.6216, val_loss: 397.5685
2022-09-26 19:51:50 | epoch: 0023/50, training time: 0.7s, inference time: 0.0s
train loss: 367.4511, val_loss: 419.9013
2022-09-26 19:51:51 | epoch: 0024/50, training time: 0.7s, inference time: 0.0s
train loss: 379.4204, val_loss: 426.0146
2022-09-26 19:51:52 | epoch: 0025/50, training time: 0.7s, inference time: 0.0s
train loss: 302.0413, val_loss: 446.8262
2022-09-26 19:51:52 | epoch: 0026/50, training time: 0.7s, inference time: 0.0s
train loss: 225.2750, val_loss: 394.7274
2022-09-26 19:51:53 | epoch: 0027/50, training time: 0.7s, inference time: 0.0s
train loss: 417.8452, val_loss: 353.3954
2022-09-26 19:51:54 | epoch: 0028/50, training time: 0.7s, inference time: 0.0s
train loss: 333.6731, val_loss: 380.3349
2022-09-26 19:51:55 | epoch: 0029/50, training time: 0.7s, inference time: 0.0s
train loss: 359.2891, val_loss: 494.5095
2022-09-26 19:51:55 | epoch: 0030/50, training time: 0.7s, inference time: 0.0s
train loss: 325.0489, val_loss: 364.4304
2022-09-26 19:51:56 | epoch: 0031/50, training time: 0.7s, inference time: 0.0s
train loss: 247.9728, val_loss: 344.3491
2022-09-26 19:51:57 | epoch: 0032/50, training time: 0.7s, inference time: 0.0s
train loss: 220.6008, val_loss: 332.8859
2022-09-26 19:51:58 | epoch: 0033/50, training time: 0.9s, inference time: 0.0s
train loss: 426.0561, val_loss: 389.6092
2022-09-26 19:51:59 | epoch: 0034/50, training time: 0.9s, inference time: 0.0s
train loss: 217.7693, val_loss: 323.9886
val loss decrease from 328.8052 to 323.9886, saving model to ./output/test-hyper-parameter(amount)_/batch_size/8/model.pkl
2022-09-26 19:52:00 | epoch: 0035/50, training time: 0.8s, inference time: 0.0s
train loss: 348.4076, val_loss: 337.9885
2022-09-26 19:52:00 | epoch: 0036/50, training time: 0.7s, inference time: 0.0s
train loss: 227.0422, val_loss: 374.7279
2022-09-26 19:52:01 | epoch: 0037/50, training time: 0.9s, inference time: 0.0s
train loss: 220.5653, val_loss: 380.8873
2022-09-26 19:52:02 | epoch: 0038/50, training time: 0.8s, inference time: 0.0s
train loss: 300.8251, val_loss: 451.8818
2022-09-26 19:52:03 | epoch: 0039/50, training time: 0.7s, inference time: 0.0s
train loss: 205.7910, val_loss: 449.3433
2022-09-26 19:52:03 | epoch: 0040/50, training time: 0.7s, inference time: 0.0s
train loss: 271.9913, val_loss: 421.7269
2022-09-26 19:52:04 | epoch: 0041/50, training time: 0.7s, inference time: 0.0s
train loss: 276.6682, val_loss: 347.9029
2022-09-26 19:52:05 | epoch: 0042/50, training time: 0.8s, inference time: 0.0s
train loss: 348.7183, val_loss: 418.0708
2022-09-26 19:52:06 | epoch: 0043/50, training time: 0.7s, inference time: 0.0s
train loss: 304.9477, val_loss: 405.9210
2022-09-26 19:52:06 | epoch: 0044/50, training time: 0.7s, inference time: 0.0s
train loss: 271.9076, val_loss: 347.5484
2022-09-26 19:52:07 | epoch: 0045/50, training time: 0.7s, inference time: 0.0s
train loss: 168.1028, val_loss: 334.2038
2022-09-26 19:52:08 | epoch: 0046/50, training time: 0.7s, inference time: 0.0s
train loss: 311.7299, val_loss: 354.2626
2022-09-26 19:52:08 | epoch: 0047/50, training time: 0.7s, inference time: 0.0s
train loss: 225.7641, val_loss: 387.5826
2022-09-26 19:52:09 | epoch: 0048/50, training time: 0.7s, inference time: 0.0s
train loss: 257.6997, val_loss: 343.0251
2022-09-26 19:52:10 | epoch: 0049/50, training time: 0.8s, inference time: 0.0s
train loss: 245.0312, val_loss: 352.0645
2022-09-26 19:52:11 | epoch: 0050/50, training time: 0.7s, inference time: 0.0s
train loss: 235.9821, val_loss: 356.3591
Training and validation are completed, and model has been stored as ./output/test-hyper-parameter(amount)_/batch_size/8/model.pkl
**** testing model ****
loading model from ./output/test-hyper-parameter(amount)_/batch_size/8/model.pkl
model restored!
evaluating...
testing time: 0.0s
                MAE		RMSE		MAPE
train            8.80		11.43		24.50%
val              15.44		18.88		39.24%
test             11.62		14.48		39.59%
performance in each prediction step
step: 01         11.62		14.48		39.59%
average:         11.62		14.48		39.59%
total time: 0.7min
