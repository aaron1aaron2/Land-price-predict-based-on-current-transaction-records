K=8, L=1, SE_file='./data/train_data/transaction_amount/SE_data/group0/SE.txt', batch_size=16, d=8, decay_epoch=10, device='cpu', learning_rate=0.001, log_file='./output/test-hyper-parameter(amount)_/batch_size/16/log.txt', max_epoch=50, model_file='./output/test-hyper-parameter(amount)_/batch_size/16/model.pkl', num_his=3, num_pred=1, output_folder='./output/test-hyper-parameter(amount)_/batch_size/16/', patience=100, test_ratio=0.1, time_slot=1440, traffic_file='./data/train_data/transaction_amount/train_data/count_group0_dist3000.h5', train_ratio=0.8, val_ratio=0.1, view_batch_freq=100
main output folder./output/test-hyper-parameter(amount)_/batch_size/16
loading data...
trainX: torch.Size([91, 3, 5])		 trainY: torch.Size([91, 1, 5])
valX:   torch.Size([8, 3, 5])		valY:   torch.Size([8, 1, 5])
testX:   torch.Size([9, 3, 5])		testY:   torch.Size([9, 1, 5])
data loaded!
compiling model...
trainable parameters: 209,923
**** training model ****
2022-09-26 19:52:17 | epoch: 0001/50, training time: 0.5s, inference time: 0.0s
train loss: 1603.9948, val_loss: 441.0317
val loss decrease from inf to 441.0317, saving model to ./output/test-hyper-parameter(amount)_/batch_size/16/model.pkl
2022-09-26 19:52:18 | epoch: 0002/50, training time: 0.5s, inference time: 0.0s
train loss: 576.9789, val_loss: 438.1253
val loss decrease from 441.0317 to 438.1253, saving model to ./output/test-hyper-parameter(amount)_/batch_size/16/model.pkl
2022-09-26 19:52:19 | epoch: 0003/50, training time: 0.7s, inference time: 0.0s
train loss: 449.9341, val_loss: 441.0050
2022-09-26 19:52:19 | epoch: 0004/50, training time: 0.6s, inference time: 0.0s
train loss: 400.9895, val_loss: 527.2423
2022-09-26 19:52:20 | epoch: 0005/50, training time: 0.6s, inference time: 0.0s
train loss: 326.8716, val_loss: 726.4061
2022-09-26 19:52:20 | epoch: 0006/50, training time: 0.6s, inference time: 0.0s
train loss: 281.9006, val_loss: 834.0602
2022-09-26 19:52:21 | epoch: 0007/50, training time: 0.5s, inference time: 0.0s
train loss: 262.5080, val_loss: 818.6827
2022-09-26 19:52:21 | epoch: 0008/50, training time: 0.5s, inference time: 0.0s
train loss: 309.3081, val_loss: 668.2487
2022-09-26 19:52:22 | epoch: 0009/50, training time: 0.4s, inference time: 0.0s
train loss: 246.6146, val_loss: 596.5175
2022-09-26 19:52:22 | epoch: 0010/50, training time: 0.4s, inference time: 0.0s
train loss: 260.9150, val_loss: 484.1425
2022-09-26 19:52:23 | epoch: 0011/50, training time: 0.4s, inference time: 0.0s
train loss: 180.6800, val_loss: 446.9331
2022-09-26 19:52:23 | epoch: 0012/50, training time: 0.4s, inference time: 0.0s
train loss: 237.4002, val_loss: 414.5692
val loss decrease from 438.1253 to 414.5692, saving model to ./output/test-hyper-parameter(amount)_/batch_size/16/model.pkl
2022-09-26 19:52:24 | epoch: 0013/50, training time: 0.4s, inference time: 0.0s
train loss: 281.3130, val_loss: 455.8402
2022-09-26 19:52:24 | epoch: 0014/50, training time: 0.4s, inference time: 0.0s
train loss: 199.0498, val_loss: 404.3266
val loss decrease from 414.5692 to 404.3266, saving model to ./output/test-hyper-parameter(amount)_/batch_size/16/model.pkl
2022-09-26 19:52:24 | epoch: 0015/50, training time: 0.4s, inference time: 0.0s
train loss: 127.0091, val_loss: 379.3441
val loss decrease from 404.3266 to 379.3441, saving model to ./output/test-hyper-parameter(amount)_/batch_size/16/model.pkl
2022-09-26 19:52:25 | epoch: 0016/50, training time: 0.4s, inference time: 0.0s
train loss: 224.8066, val_loss: 366.7415
val loss decrease from 379.3441 to 366.7415, saving model to ./output/test-hyper-parameter(amount)_/batch_size/16/model.pkl
2022-09-26 19:52:25 | epoch: 0017/50, training time: 0.4s, inference time: 0.0s
train loss: 184.0670, val_loss: 386.7011
2022-09-26 19:52:26 | epoch: 0018/50, training time: 0.5s, inference time: 0.0s
train loss: 169.4014, val_loss: 428.8334
2022-09-26 19:52:26 | epoch: 0019/50, training time: 0.4s, inference time: 0.0s
train loss: 197.2884, val_loss: 438.6059
2022-09-26 19:52:27 | epoch: 0020/50, training time: 0.4s, inference time: 0.0s
train loss: 232.8854, val_loss: 394.7308
2022-09-26 19:52:27 | epoch: 0021/50, training time: 0.4s, inference time: 0.0s
train loss: 171.2416, val_loss: 430.3417
2022-09-26 19:52:28 | epoch: 0022/50, training time: 0.4s, inference time: 0.0s
train loss: 157.2710, val_loss: 399.0684
2022-09-26 19:52:28 | epoch: 0023/50, training time: 0.4s, inference time: 0.0s
train loss: 144.7230, val_loss: 406.9846
2022-09-26 19:52:28 | epoch: 0024/50, training time: 0.4s, inference time: 0.0s
train loss: 113.5584, val_loss: 405.8776
2022-09-26 19:52:29 | epoch: 0025/50, training time: 0.4s, inference time: 0.0s
train loss: 340.8624, val_loss: 384.5675
2022-09-26 19:52:29 | epoch: 0026/50, training time: 0.4s, inference time: 0.0s
train loss: 141.2164, val_loss: 350.6829
val loss decrease from 366.7415 to 350.6829, saving model to ./output/test-hyper-parameter(amount)_/batch_size/16/model.pkl
2022-09-26 19:52:30 | epoch: 0027/50, training time: 0.4s, inference time: 0.0s
train loss: 249.2803, val_loss: 317.0547
val loss decrease from 350.6829 to 317.0547, saving model to ./output/test-hyper-parameter(amount)_/batch_size/16/model.pkl
2022-09-26 19:52:30 | epoch: 0028/50, training time: 0.4s, inference time: 0.0s
train loss: 176.0542, val_loss: 377.7484
2022-09-26 19:52:30 | epoch: 0029/50, training time: 0.4s, inference time: 0.0s
train loss: 139.3512, val_loss: 524.5053
2022-09-26 19:52:31 | epoch: 0030/50, training time: 0.4s, inference time: 0.0s
train loss: 210.8530, val_loss: 583.6757
2022-09-26 19:52:31 | epoch: 0031/50, training time: 0.4s, inference time: 0.0s
train loss: 109.5435, val_loss: 543.7286
2022-09-26 19:52:32 | epoch: 0032/50, training time: 0.4s, inference time: 0.0s
train loss: 122.4236, val_loss: 489.3115
2022-09-26 19:52:32 | epoch: 0033/50, training time: 0.4s, inference time: 0.0s
train loss: 236.6829, val_loss: 462.0452
2022-09-26 19:52:33 | epoch: 0034/50, training time: 0.4s, inference time: 0.0s
train loss: 134.7354, val_loss: 451.4596
2022-09-26 19:52:33 | epoch: 0035/50, training time: 0.4s, inference time: 0.0s
train loss: 205.9481, val_loss: 522.9899
2022-09-26 19:52:33 | epoch: 0036/50, training time: 0.4s, inference time: 0.0s
train loss: 162.1446, val_loss: 490.8077
2022-09-26 19:52:34 | epoch: 0037/50, training time: 0.4s, inference time: 0.0s
train loss: 144.0397, val_loss: 429.2624
2022-09-26 19:52:34 | epoch: 0038/50, training time: 0.4s, inference time: 0.0s
train loss: 133.8449, val_loss: 384.2499
2022-09-26 19:52:35 | epoch: 0039/50, training time: 0.4s, inference time: 0.0s
train loss: 129.9032, val_loss: 378.2494
2022-09-26 19:52:35 | epoch: 0040/50, training time: 0.4s, inference time: 0.0s
train loss: 155.5060, val_loss: 419.3497
2022-09-26 19:52:36 | epoch: 0041/50, training time: 0.4s, inference time: 0.0s
train loss: 139.4269, val_loss: 477.2607
2022-09-26 19:52:36 | epoch: 0042/50, training time: 0.4s, inference time: 0.0s
train loss: 106.7061, val_loss: 427.5050
2022-09-26 19:52:36 | epoch: 0043/50, training time: 0.4s, inference time: 0.0s
train loss: 152.2685, val_loss: 398.1727
2022-09-26 19:52:37 | epoch: 0044/50, training time: 0.4s, inference time: 0.0s
train loss: 164.6440, val_loss: 376.3520
2022-09-26 19:52:37 | epoch: 0045/50, training time: 0.4s, inference time: 0.0s
train loss: 84.5364, val_loss: 354.3616
2022-09-26 19:52:38 | epoch: 0046/50, training time: 0.4s, inference time: 0.0s
train loss: 280.1568, val_loss: 414.0244
2022-09-26 19:52:38 | epoch: 0047/50, training time: 0.4s, inference time: 0.0s
train loss: 70.4430, val_loss: 422.9483
2022-09-26 19:52:39 | epoch: 0048/50, training time: 0.4s, inference time: 0.0s
train loss: 118.0230, val_loss: 341.8323
2022-09-26 19:52:39 | epoch: 0049/50, training time: 0.4s, inference time: 0.0s
train loss: 116.8045, val_loss: 312.4659
val loss decrease from 317.0547 to 312.4659, saving model to ./output/test-hyper-parameter(amount)_/batch_size/16/model.pkl
2022-09-26 19:52:39 | epoch: 0050/50, training time: 0.4s, inference time: 0.0s
train loss: 240.3055, val_loss: 341.0510
Training and validation are completed, and model has been stored as ./output/test-hyper-parameter(amount)_/batch_size/16/model.pkl
**** testing model ****
loading model from ./output/test-hyper-parameter(amount)_/batch_size/16/model.pkl
model restored!
evaluating...
testing time: 0.0s
                MAE		RMSE		MAPE
train            5.41		7.47		13.23%
val              15.35		18.47		36.43%
test             10.59		12.86		31.65%
performance in each prediction step
step: 01         10.59		12.86		31.65%
average:         10.59		12.86		31.65%
total time: 0.4min
