K=8, L=1, SE_file='./data/train_data/transaction_amount/SE_data/group0/SE.txt', batch_size=16, d=8, decay_epoch=10, device='cpu', learning_rate=0.0001, log_file='./output/test-hyper-parameter(amount)_/learning_rate/0.0001/log.txt', max_epoch=50, model_file='./output/test-hyper-parameter(amount)_/learning_rate/0.0001/model.pkl', num_his=3, num_pred=1, output_folder='./output/test-hyper-parameter(amount)_/learning_rate/0.0001', patience=100, test_ratio=0.1, time_slot=1440, traffic_file='./data/train_data/transaction_amount/train_data/count_group0_dist3000.h5', train_ratio=0.8, val_ratio=0.1, view_batch_freq=100
main output folder./output/test-hyper-parameter(amount)_/learning_rate/0.0001
loading data...
trainX: torch.Size([91, 3, 5])		 trainY: torch.Size([91, 1, 5])
valX:   torch.Size([8, 3, 5])		valY:   torch.Size([8, 1, 5])
testX:   torch.Size([9, 3, 5])		testY:   torch.Size([9, 1, 5])
data loaded!
compiling model...
trainable parameters: 209,923
**** training model ****
2022-09-26 19:54:24 | epoch: 0001/50, training time: 0.6s, inference time: 0.0s
train loss: 2235.8337, val_loss: 462.3468
val loss decrease from inf to 462.3468, saving model to ./output/test-hyper-parameter(amount)_/learning_rate/0.0001/model.pkl
2022-09-26 19:54:24 | epoch: 0002/50, training time: 0.5s, inference time: 0.0s
train loss: 1691.1588, val_loss: 455.3476
val loss decrease from 462.3468 to 455.3476, saving model to ./output/test-hyper-parameter(amount)_/learning_rate/0.0001/model.pkl
2022-09-26 19:54:25 | epoch: 0003/50, training time: 0.7s, inference time: 0.0s
train loss: 1251.0049, val_loss: 1085.6721
2022-09-26 19:54:25 | epoch: 0004/50, training time: 0.6s, inference time: 0.0s
train loss: 929.8733, val_loss: 1754.3184
2022-09-26 19:54:26 | epoch: 0005/50, training time: 0.6s, inference time: 0.0s
train loss: 840.0785, val_loss: 1438.1511
2022-09-26 19:54:27 | epoch: 0006/50, training time: 0.6s, inference time: 0.0s
train loss: 733.4372, val_loss: 1095.7068
2022-09-26 19:54:27 | epoch: 0007/50, training time: 0.7s, inference time: 0.0s
train loss: 729.5876, val_loss: 841.6798
2022-09-26 19:54:28 | epoch: 0008/50, training time: 0.7s, inference time: 0.0s
train loss: 624.7718, val_loss: 691.8783
2022-09-26 19:54:29 | epoch: 0009/50, training time: 0.7s, inference time: 0.0s
train loss: 681.1500, val_loss: 583.1400
2022-09-26 19:54:30 | epoch: 0010/50, training time: 0.8s, inference time: 0.0s
train loss: 574.7660, val_loss: 534.8102
2022-09-26 19:54:31 | epoch: 0011/50, training time: 0.7s, inference time: 0.0s
train loss: 587.9010, val_loss: 583.6527
2022-09-26 19:54:31 | epoch: 0012/50, training time: 0.8s, inference time: 0.0s
train loss: 532.0284, val_loss: 610.3885
2022-09-26 19:54:32 | epoch: 0013/50, training time: 0.7s, inference time: 0.0s
train loss: 576.4059, val_loss: 654.9231
2022-09-26 19:54:33 | epoch: 0014/50, training time: 0.7s, inference time: 0.0s
train loss: 549.0596, val_loss: 627.9615
2022-09-26 19:54:34 | epoch: 0015/50, training time: 0.8s, inference time: 0.0s
train loss: 424.3824, val_loss: 553.1493
2022-09-26 19:54:35 | epoch: 0016/50, training time: 0.8s, inference time: 0.0s
train loss: 491.1351, val_loss: 542.2654
2022-09-26 19:54:35 | epoch: 0017/50, training time: 0.8s, inference time: 0.0s
train loss: 445.9017, val_loss: 525.0512
2022-09-26 19:54:36 | epoch: 0018/50, training time: 0.8s, inference time: 0.0s
train loss: 465.3614, val_loss: 518.7615
2022-09-26 19:54:37 | epoch: 0019/50, training time: 0.9s, inference time: 0.0s
train loss: 371.8410, val_loss: 494.6656
2022-09-26 19:54:38 | epoch: 0020/50, training time: 0.8s, inference time: 0.0s
train loss: 444.6196, val_loss: 482.8186
2022-09-26 19:54:39 | epoch: 0021/50, training time: 0.7s, inference time: 0.0s
train loss: 486.3895, val_loss: 484.8987
2022-09-26 19:54:39 | epoch: 0022/50, training time: 0.8s, inference time: 0.0s
train loss: 444.4197, val_loss: 507.9835
2022-09-26 19:54:40 | epoch: 0023/50, training time: 0.7s, inference time: 0.0s
train loss: 439.3035, val_loss: 489.9503
2022-09-26 19:54:41 | epoch: 0024/50, training time: 0.7s, inference time: 0.0s
train loss: 328.7706, val_loss: 506.5391
2022-09-26 19:54:42 | epoch: 0025/50, training time: 0.8s, inference time: 0.0s
train loss: 469.3861, val_loss: 532.8922
2022-09-26 19:54:43 | epoch: 0026/50, training time: 0.7s, inference time: 0.0s
train loss: 272.8938, val_loss: 523.9214
2022-09-26 19:54:43 | epoch: 0027/50, training time: 0.8s, inference time: 0.0s
train loss: 425.6238, val_loss: 504.5061
2022-09-26 19:54:44 | epoch: 0028/50, training time: 0.7s, inference time: 0.0s
train loss: 354.8707, val_loss: 479.9821
2022-09-26 19:54:45 | epoch: 0029/50, training time: 0.7s, inference time: 0.0s
train loss: 376.6594, val_loss: 436.7184
val loss decrease from 455.3476 to 436.7184, saving model to ./output/test-hyper-parameter(amount)_/learning_rate/0.0001/model.pkl
2022-09-26 19:54:46 | epoch: 0030/50, training time: 0.8s, inference time: 0.0s
train loss: 379.9897, val_loss: 489.3971
2022-09-26 19:54:46 | epoch: 0031/50, training time: 0.7s, inference time: 0.0s
train loss: 335.5192, val_loss: 497.3607
2022-09-26 19:54:47 | epoch: 0032/50, training time: 0.8s, inference time: 0.0s
train loss: 310.4353, val_loss: 482.2500
2022-09-26 19:54:48 | epoch: 0033/50, training time: 0.8s, inference time: 0.0s
train loss: 346.7655, val_loss: 453.7594
2022-09-26 19:54:49 | epoch: 0034/50, training time: 0.7s, inference time: 0.0s
train loss: 384.4741, val_loss: 456.1003
2022-09-26 19:54:50 | epoch: 0035/50, training time: 0.8s, inference time: 0.0s
train loss: 371.2117, val_loss: 453.4367
2022-09-26 19:54:50 | epoch: 0036/50, training time: 0.7s, inference time: 0.0s
train loss: 300.1942, val_loss: 445.7824
2022-09-26 19:54:51 | epoch: 0037/50, training time: 0.7s, inference time: 0.0s
train loss: 308.0542, val_loss: 437.2207
2022-09-26 19:54:52 | epoch: 0038/50, training time: 0.7s, inference time: 0.0s
train loss: 274.2891, val_loss: 410.7201
val loss decrease from 436.7184 to 410.7201, saving model to ./output/test-hyper-parameter(amount)_/learning_rate/0.0001/model.pkl
2022-09-26 19:54:53 | epoch: 0039/50, training time: 0.7s, inference time: 0.0s
train loss: 387.7619, val_loss: 426.3989
2022-09-26 19:54:54 | epoch: 0040/50, training time: 0.8s, inference time: 0.0s
train loss: 354.0697, val_loss: 423.7969
2022-09-26 19:54:54 | epoch: 0041/50, training time: 0.8s, inference time: 0.0s
train loss: 296.4897, val_loss: 420.2797
2022-09-26 19:54:55 | epoch: 0042/50, training time: 0.7s, inference time: 0.0s
train loss: 266.4455, val_loss: 446.9581
2022-09-26 19:54:56 | epoch: 0043/50, training time: 0.7s, inference time: 0.0s
train loss: 434.9320, val_loss: 453.4663
2022-09-26 19:54:57 | epoch: 0044/50, training time: 0.7s, inference time: 0.0s
train loss: 340.6261, val_loss: 453.4800
2022-09-26 19:54:58 | epoch: 0045/50, training time: 0.8s, inference time: 0.0s
train loss: 270.2878, val_loss: 470.0270
2022-09-26 19:54:58 | epoch: 0046/50, training time: 0.7s, inference time: 0.0s
train loss: 354.6853, val_loss: 449.9682
2022-09-26 19:54:59 | epoch: 0047/50, training time: 0.7s, inference time: 0.0s
train loss: 292.0878, val_loss: 452.5251
2022-09-26 19:55:00 | epoch: 0048/50, training time: 0.8s, inference time: 0.0s
train loss: 266.5714, val_loss: 470.1080
2022-09-26 19:55:01 | epoch: 0049/50, training time: 0.7s, inference time: 0.0s
train loss: 265.8416, val_loss: 499.9182
2022-09-26 19:55:01 | epoch: 0050/50, training time: 0.7s, inference time: 0.0s
train loss: 341.8404, val_loss: 472.1120
Training and validation are completed, and model has been stored as ./output/test-hyper-parameter(amount)_/learning_rate/0.0001/model.pkl
**** testing model ****
loading model from ./output/test-hyper-parameter(amount)_/learning_rate/0.0001/model.pkl
model restored!
evaluating...
testing time: 0.0s
                MAE		RMSE		MAPE
train            11.93		14.94		32.16%
val              18.03		21.73		46.25%
test             13.58		16.18		40.72%
performance in each prediction step
step: 01         13.58		16.18		40.72%
average:         13.58		16.18		40.72%
total time: 0.7min
