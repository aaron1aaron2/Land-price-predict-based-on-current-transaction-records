K=8, L=1, SE_file='./data/train_data/transaction_amount/SE_data/group0/SE.txt', batch_size=16, d=8, decay_epoch=10, device='cpu', learning_rate=0.01, log_file='./output/test-hyper-parameter(amount)_/learning_rate/0.01/log.txt', max_epoch=50, model_file='./output/test-hyper-parameter(amount)_/learning_rate/0.01/model.pkl', num_his=3, num_pred=1, output_folder='./output/test-hyper-parameter(amount)_/learning_rate/0.01', patience=100, test_ratio=0.1, time_slot=1440, traffic_file='./data/train_data/transaction_amount/train_data/count_group0_dist3000.h5', train_ratio=0.8, val_ratio=0.1, view_batch_freq=100
main output folder./output/test-hyper-parameter(amount)_/learning_rate/0.01
loading data...
trainX: torch.Size([91, 3, 5])		 trainY: torch.Size([91, 1, 5])
valX:   torch.Size([8, 3, 5])		valY:   torch.Size([8, 1, 5])
testX:   torch.Size([9, 3, 5])		testY:   torch.Size([9, 1, 5])
data loaded!
compiling model...
trainable parameters: 209,923
**** training model ****
2022-09-26 19:53:09 | epoch: 0001/50, training time: 0.6s, inference time: 0.0s
train loss: 953.4069, val_loss: 443.2361
val loss decrease from inf to 443.2361, saving model to ./output/test-hyper-parameter(amount)_/learning_rate/0.01/model.pkl
2022-09-26 19:53:10 | epoch: 0002/50, training time: 0.5s, inference time: 0.0s
train loss: 437.5812, val_loss: 583.0705
2022-09-26 19:53:11 | epoch: 0003/50, training time: 0.7s, inference time: 0.0s
train loss: 406.3607, val_loss: 567.5577
2022-09-26 19:53:11 | epoch: 0004/50, training time: 0.6s, inference time: 0.0s
train loss: 291.1008, val_loss: 561.9717
2022-09-26 19:53:12 | epoch: 0005/50, training time: 0.5s, inference time: 0.0s
train loss: 313.3559, val_loss: 507.0378
2022-09-26 19:53:12 | epoch: 0006/50, training time: 0.6s, inference time: 0.0s
train loss: 293.1481, val_loss: 535.1240
2022-09-26 19:53:13 | epoch: 0007/50, training time: 0.5s, inference time: 0.0s
train loss: 386.2305, val_loss: 459.2967
2022-09-26 19:53:13 | epoch: 0008/50, training time: 0.4s, inference time: 0.0s
train loss: 393.2488, val_loss: 486.4856
2022-09-26 19:53:14 | epoch: 0009/50, training time: 0.4s, inference time: 0.0s
train loss: 463.1552, val_loss: 442.1847
val loss decrease from 443.2361 to 442.1847, saving model to ./output/test-hyper-parameter(amount)_/learning_rate/0.01/model.pkl
2022-09-26 19:53:14 | epoch: 0010/50, training time: 0.4s, inference time: 0.0s
train loss: 312.2806, val_loss: 474.4277
2022-09-26 19:53:15 | epoch: 0011/50, training time: 0.4s, inference time: 0.0s
train loss: 210.1347, val_loss: 402.6176
val loss decrease from 442.1847 to 402.6176, saving model to ./output/test-hyper-parameter(amount)_/learning_rate/0.01/model.pkl
2022-09-26 19:53:15 | epoch: 0012/50, training time: 0.4s, inference time: 0.0s
train loss: 215.4444, val_loss: 394.8823
val loss decrease from 402.6176 to 394.8823, saving model to ./output/test-hyper-parameter(amount)_/learning_rate/0.01/model.pkl
2022-09-26 19:53:16 | epoch: 0013/50, training time: 0.4s, inference time: 0.0s
train loss: 184.5316, val_loss: 360.9693
val loss decrease from 394.8823 to 360.9693, saving model to ./output/test-hyper-parameter(amount)_/learning_rate/0.01/model.pkl
2022-09-26 19:53:16 | epoch: 0014/50, training time: 0.5s, inference time: 0.0s
train loss: 248.6051, val_loss: 335.1299
val loss decrease from 360.9693 to 335.1299, saving model to ./output/test-hyper-parameter(amount)_/learning_rate/0.01/model.pkl
2022-09-26 19:53:17 | epoch: 0015/50, training time: 0.4s, inference time: 0.0s
train loss: 205.6833, val_loss: 274.1728
val loss decrease from 335.1299 to 274.1728, saving model to ./output/test-hyper-parameter(amount)_/learning_rate/0.01/model.pkl
2022-09-26 19:53:17 | epoch: 0016/50, training time: 0.4s, inference time: 0.0s
train loss: 159.0520, val_loss: 330.2167
2022-09-26 19:53:18 | epoch: 0017/50, training time: 0.4s, inference time: 0.0s
train loss: 225.5309, val_loss: 381.8981
2022-09-26 19:53:18 | epoch: 0018/50, training time: 0.4s, inference time: 0.0s
train loss: 127.4882, val_loss: 370.2261
2022-09-26 19:53:18 | epoch: 0019/50, training time: 0.4s, inference time: 0.0s
train loss: 130.5976, val_loss: 332.8415
2022-09-26 19:53:19 | epoch: 0020/50, training time: 0.4s, inference time: 0.0s
train loss: 180.1017, val_loss: 303.7621
2022-09-26 19:53:19 | epoch: 0021/50, training time: 0.4s, inference time: 0.0s
train loss: 253.6689, val_loss: 285.2769
2022-09-26 19:53:20 | epoch: 0022/50, training time: 0.4s, inference time: 0.0s
train loss: 217.7425, val_loss: 311.8350
2022-09-26 19:53:20 | epoch: 0023/50, training time: 0.4s, inference time: 0.0s
train loss: 190.6254, val_loss: 333.4325
2022-09-26 19:53:20 | epoch: 0024/50, training time: 0.4s, inference time: 0.0s
train loss: 311.1819, val_loss: 375.8493
2022-09-26 19:53:21 | epoch: 0025/50, training time: 0.4s, inference time: 0.0s
train loss: 177.4029, val_loss: 410.1072
2022-09-26 19:53:21 | epoch: 0026/50, training time: 0.5s, inference time: 0.0s
train loss: 191.0518, val_loss: 294.7769
2022-09-26 19:53:22 | epoch: 0027/50, training time: 0.4s, inference time: 0.0s
train loss: 144.0716, val_loss: 276.1336
2022-09-26 19:53:22 | epoch: 0028/50, training time: 0.4s, inference time: 0.0s
train loss: 85.0508, val_loss: 384.5966
2022-09-26 19:53:23 | epoch: 0029/50, training time: 0.4s, inference time: 0.0s
train loss: 257.9363, val_loss: 408.1407
2022-09-26 19:53:23 | epoch: 0030/50, training time: 0.4s, inference time: 0.0s
train loss: 118.2244, val_loss: 305.0467
2022-09-26 19:53:24 | epoch: 0031/50, training time: 0.4s, inference time: 0.0s
train loss: 121.9860, val_loss: 267.5609
val loss decrease from 274.1728 to 267.5609, saving model to ./output/test-hyper-parameter(amount)_/learning_rate/0.01/model.pkl
2022-09-26 19:53:24 | epoch: 0032/50, training time: 0.4s, inference time: 0.0s
train loss: 122.7005, val_loss: 332.2674
2022-09-26 19:53:24 | epoch: 0033/50, training time: 0.4s, inference time: 0.0s
train loss: 137.5748, val_loss: 397.8912
2022-09-26 19:53:25 | epoch: 0034/50, training time: 0.5s, inference time: 0.0s
train loss: 132.6986, val_loss: 398.8652
2022-09-26 19:53:25 | epoch: 0035/50, training time: 0.5s, inference time: 0.0s
train loss: 176.5989, val_loss: 334.2087
2022-09-26 19:53:26 | epoch: 0036/50, training time: 0.4s, inference time: 0.0s
train loss: 209.3367, val_loss: 330.7531
2022-09-26 19:53:26 | epoch: 0037/50, training time: 0.4s, inference time: 0.0s
train loss: 138.6155, val_loss: 275.6157
2022-09-26 19:53:27 | epoch: 0038/50, training time: 0.4s, inference time: 0.0s
train loss: 101.1904, val_loss: 290.6037
2022-09-26 19:53:27 | epoch: 0039/50, training time: 0.5s, inference time: 0.0s
train loss: 80.4651, val_loss: 315.5512
2022-09-26 19:53:28 | epoch: 0040/50, training time: 0.4s, inference time: 0.0s
train loss: 134.3730, val_loss: 275.9238
2022-09-26 19:53:28 | epoch: 0041/50, training time: 0.5s, inference time: 0.0s
train loss: 76.1334, val_loss: 282.5289
2022-09-26 19:53:29 | epoch: 0042/50, training time: 0.4s, inference time: 0.0s
train loss: 122.0206, val_loss: 311.5464
2022-09-26 19:53:29 | epoch: 0043/50, training time: 0.4s, inference time: 0.0s
train loss: 90.1137, val_loss: 316.3648
2022-09-26 19:53:29 | epoch: 0044/50, training time: 0.4s, inference time: 0.0s
train loss: 90.9124, val_loss: 326.8104
2022-09-26 19:53:30 | epoch: 0045/50, training time: 0.4s, inference time: 0.0s
train loss: 183.5231, val_loss: 317.3281
2022-09-26 19:53:30 | epoch: 0046/50, training time: 0.4s, inference time: 0.0s
train loss: 131.8181, val_loss: 297.3196
2022-09-26 19:53:31 | epoch: 0047/50, training time: 0.4s, inference time: 0.0s
train loss: 62.6136, val_loss: 281.4073
2022-09-26 19:53:31 | epoch: 0048/50, training time: 0.4s, inference time: 0.0s
train loss: 93.2051, val_loss: 243.9279
val loss decrease from 267.5609 to 243.9279, saving model to ./output/test-hyper-parameter(amount)_/learning_rate/0.01/model.pkl
2022-09-26 19:53:32 | epoch: 0049/50, training time: 0.4s, inference time: 0.0s
train loss: 132.1947, val_loss: 293.2061
2022-09-26 19:53:32 | epoch: 0050/50, training time: 0.4s, inference time: 0.0s
train loss: 100.7460, val_loss: 315.7580
Training and validation are completed, and model has been stored as ./output/test-hyper-parameter(amount)_/learning_rate/0.01/model.pkl
**** testing model ****
loading model from ./output/test-hyper-parameter(amount)_/learning_rate/0.01/model.pkl
model restored!
evaluating...
testing time: 0.0s
                MAE		RMSE		MAPE
train            4.46		6.13		12.99%
val              15.52		17.77		35.83%
test             13.62		16.94		45.04%
performance in each prediction step
step: 01         13.62		16.94		45.04%
average:         13.62		16.94		45.04%
total time: 0.4min
