K=8, L=1, SE_file='./data/train_data/basic/SE_data/group0/SE.txt', batch_size=4, d=8, decay_epoch=10, device='cpu', learning_rate=0.001, log_file='./output/test-hyper-parameter/batch_size/4/log.txt', max_epoch=50, model_file='./output/test-hyper-parameter/batch_size/4/model.pkl', num_his=5, num_pred=1, output_folder='./output/test-hyper-parameter/batch_size/4/', patience=100, test_ratio=0.1, time_slot=1440, traffic_file='./data/train_data/basic/train_data/mean_group0_dist3000.h5', train_ratio=0.8, val_ratio=0.1, view_batch_freq=100
main output folder./output/test-hyper-parameter/batch_size/4
loading data...
trainX: torch.Size([89, 5, 5])		 trainY: torch.Size([89, 1, 5])
valX:   torch.Size([6, 5, 5])		valY:   torch.Size([6, 1, 5])
testX:   torch.Size([7, 5, 5])		testY:   torch.Size([7, 1, 5])
data loaded!
compiling model...
trainable parameters: 209,923
**** training model ****
2022-09-25 17:38:58 | epoch: 0001/50, training time: 1.4s, inference time: 0.1s
train loss: 175858686.0225, val_loss: 206166720.0000
val loss decrease from inf to 206166720.0000, saving model to ./output/test-hyper-parameter/batch_size/4/model.pkl
2022-09-25 17:39:00 | epoch: 0002/50, training time: 1.5s, inference time: 0.0s
train loss: 129070726.4719, val_loss: 154834608.0000
val loss decrease from 206166720.0000 to 154834608.0000, saving model to ./output/test-hyper-parameter/batch_size/4/model.pkl
2022-09-25 17:39:01 | epoch: 0003/50, training time: 1.2s, inference time: 0.0s
train loss: 114613752.0899, val_loss: 131638408.0000
val loss decrease from 154834608.0000 to 131638408.0000, saving model to ./output/test-hyper-parameter/batch_size/4/model.pkl
2022-09-25 17:39:02 | epoch: 0004/50, training time: 1.1s, inference time: 0.0s
train loss: 113738385.4382, val_loss: 135789664.0000
2022-09-25 17:39:03 | epoch: 0005/50, training time: 1.1s, inference time: 0.0s
train loss: 106003296.0000, val_loss: 134474128.0000
2022-09-25 17:39:05 | epoch: 0006/50, training time: 1.1s, inference time: 0.0s
train loss: 97599406.9213, val_loss: 151605664.0000
2022-09-25 17:39:06 | epoch: 0007/50, training time: 1.5s, inference time: 0.0s
train loss: 97158151.6180, val_loss: 158139104.0000
2022-09-25 17:39:07 | epoch: 0008/50, training time: 1.1s, inference time: 0.0s
train loss: 96707710.0225, val_loss: 166096464.0000
2022-09-25 17:39:08 | epoch: 0009/50, training time: 1.2s, inference time: 0.0s
train loss: 96150399.1910, val_loss: 166343424.0000
2022-09-25 17:39:09 | epoch: 0010/50, training time: 1.1s, inference time: 0.0s
train loss: 91768856.0899, val_loss: 133481280.0000
2022-09-25 17:39:11 | epoch: 0011/50, training time: 1.1s, inference time: 0.0s
train loss: 93136260.6742, val_loss: 144500416.0000
2022-09-25 17:39:12 | epoch: 0012/50, training time: 1.1s, inference time: 0.0s
train loss: 87205870.3820, val_loss: 139847360.0000
2022-09-25 17:39:13 | epoch: 0013/50, training time: 1.0s, inference time: 0.0s
train loss: 93547146.6517, val_loss: 147471600.0000
2022-09-25 17:39:14 | epoch: 0014/50, training time: 1.1s, inference time: 0.0s
train loss: 89131434.9663, val_loss: 145719888.0000
2022-09-25 17:39:15 | epoch: 0015/50, training time: 1.1s, inference time: 0.0s
train loss: 84551679.1011, val_loss: 155292384.0000
2022-09-25 17:39:16 | epoch: 0016/50, training time: 1.1s, inference time: 0.0s
train loss: 83613367.1011, val_loss: 135294704.0000
2022-09-25 17:39:17 | epoch: 0017/50, training time: 1.0s, inference time: 0.0s
train loss: 81247827.2360, val_loss: 128256648.0000
val loss decrease from 131638408.0000 to 128256648.0000, saving model to ./output/test-hyper-parameter/batch_size/4/model.pkl
2022-09-25 17:39:18 | epoch: 0018/50, training time: 1.1s, inference time: 0.0s
train loss: 86133902.7191, val_loss: 148133008.0000
2022-09-25 17:39:19 | epoch: 0019/50, training time: 1.0s, inference time: 0.0s
train loss: 77763239.5506, val_loss: 146718992.0000
2022-09-25 17:39:20 | epoch: 0020/50, training time: 1.1s, inference time: 0.0s
train loss: 76210614.8539, val_loss: 135490496.0000
2022-09-25 17:39:21 | epoch: 0021/50, training time: 1.1s, inference time: 0.0s
train loss: 74615855.1011, val_loss: 134157400.0000
2022-09-25 17:39:23 | epoch: 0022/50, training time: 1.1s, inference time: 0.0s
train loss: 68147936.6292, val_loss: 140897008.0000
2022-09-25 17:39:24 | epoch: 0023/50, training time: 1.1s, inference time: 0.0s
train loss: 67040887.5506, val_loss: 158897680.0000
2022-09-25 17:39:25 | epoch: 0024/50, training time: 1.1s, inference time: 0.0s
train loss: 71008311.0112, val_loss: 147204816.0000
2022-09-25 17:39:26 | epoch: 0025/50, training time: 1.0s, inference time: 0.0s
train loss: 70622828.5843, val_loss: 148250496.0000
2022-09-25 17:39:27 | epoch: 0026/50, training time: 1.1s, inference time: 0.0s
train loss: 71329926.8315, val_loss: 157957568.0000
2022-09-25 17:39:28 | epoch: 0027/50, training time: 1.0s, inference time: 0.0s
train loss: 73578329.9438, val_loss: 155271488.0000
2022-09-25 17:39:29 | epoch: 0028/50, training time: 1.0s, inference time: 0.0s
train loss: 75259595.8652, val_loss: 158131664.0000
2022-09-25 17:39:30 | epoch: 0029/50, training time: 1.0s, inference time: 0.0s
train loss: 65080258.6067, val_loss: 176383088.0000
2022-09-25 17:39:31 | epoch: 0030/50, training time: 1.0s, inference time: 0.0s
train loss: 63595135.1461, val_loss: 166091648.0000
2022-09-25 17:39:32 | epoch: 0031/50, training time: 1.1s, inference time: 0.0s
train loss: 59864637.4382, val_loss: 149703936.0000
2022-09-25 17:39:34 | epoch: 0032/50, training time: 1.2s, inference time: 0.0s
train loss: 66156896.0000, val_loss: 136247984.0000
2022-09-25 17:39:35 | epoch: 0033/50, training time: 1.2s, inference time: 0.0s
train loss: 67125084.4494, val_loss: 154054544.0000
2022-09-25 17:39:36 | epoch: 0034/50, training time: 1.1s, inference time: 0.0s
train loss: 58768946.4270, val_loss: 146134784.0000
2022-09-25 17:39:37 | epoch: 0035/50, training time: 1.2s, inference time: 0.0s
train loss: 63698943.9101, val_loss: 143853680.0000
2022-09-25 17:39:39 | epoch: 0036/50, training time: 1.2s, inference time: 0.0s
train loss: 62111925.6180, val_loss: 168545488.0000
2022-09-25 17:39:40 | epoch: 0037/50, training time: 1.1s, inference time: 0.0s
train loss: 55940616.2697, val_loss: 189282816.0000
2022-09-25 17:39:41 | epoch: 0038/50, training time: 1.2s, inference time: 0.0s
train loss: 52957073.8876, val_loss: 176097904.0000
2022-09-25 17:39:42 | epoch: 0039/50, training time: 1.2s, inference time: 0.0s
train loss: 61578773.0337, val_loss: 189602512.0000
2022-09-25 17:39:43 | epoch: 0040/50, training time: 1.2s, inference time: 0.0s
train loss: 57520379.9551, val_loss: 175729632.0000
2022-09-25 17:39:45 | epoch: 0041/50, training time: 1.2s, inference time: 0.0s
train loss: 57627574.8315, val_loss: 181224704.0000
2022-09-25 17:39:46 | epoch: 0042/50, training time: 1.2s, inference time: 0.0s
train loss: 58432556.6292, val_loss: 193175664.0000
2022-09-25 17:39:47 | epoch: 0043/50, training time: 1.3s, inference time: 0.0s
train loss: 55066509.8427, val_loss: 178542512.0000
2022-09-25 17:39:48 | epoch: 0044/50, training time: 1.3s, inference time: 0.0s
train loss: 56626959.5506, val_loss: 171833312.0000
2022-09-25 17:39:50 | epoch: 0045/50, training time: 1.2s, inference time: 0.0s
train loss: 56524414.8708, val_loss: 176346128.0000
2022-09-25 17:39:51 | epoch: 0046/50, training time: 1.2s, inference time: 0.0s
train loss: 58983652.3146, val_loss: 149548560.0000
2022-09-25 17:39:52 | epoch: 0047/50, training time: 1.2s, inference time: 0.0s
train loss: 45625305.9888, val_loss: 161661184.0000
2022-09-25 17:39:53 | epoch: 0048/50, training time: 1.2s, inference time: 0.0s
train loss: 50908958.7865, val_loss: 157082352.0000
2022-09-25 17:39:55 | epoch: 0049/50, training time: 1.2s, inference time: 0.0s
train loss: 48417501.6854, val_loss: 151355904.0000
2022-09-25 17:39:56 | epoch: 0050/50, training time: 1.2s, inference time: 0.0s
train loss: 49180003.9551, val_loss: 158333360.0000
Training and validation are completed, and model has been stored as ./output/test-hyper-parameter/batch_size/4/model.pkl
**** testing model ****
loading model from ./output/test-hyper-parameter/batch_size/4/model.pkl
model restored!
evaluating...
testing time: 0.0s
                MAE		RMSE		MAPE
train            4869.07		6222.95		9.19%
val              9219.51		12583.06		16.05%
test             8915.40		10318.64		14.90%
performance in each prediction step
step: 01         8915.40		10318.64		14.90%
average:         8915.40		10318.64		14.90%
total time: 1.0min
