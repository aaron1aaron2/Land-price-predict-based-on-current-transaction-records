K=8, L=1, SE_file='./data/train_data/basic/SE_data/group0/SE.txt', batch_size=8, d=8, decay_epoch=10, device='cpu', learning_rate=0.001, log_file='./output/test-hyper-parameter/batch_size/8/log.txt', max_epoch=50, model_file='./output/test-hyper-parameter/batch_size/8/model.pkl', num_his=5, num_pred=1, output_folder='./output/test-hyper-parameter/batch_size/8/', patience=100, test_ratio=0.1, time_slot=1440, traffic_file='./data/train_data/basic/train_data/mean_group0_dist3000.h5', train_ratio=0.8, val_ratio=0.1, view_batch_freq=100
main output folder./output/test-hyper-parameter/batch_size/8
loading data...
trainX: torch.Size([89, 5, 5])		 trainY: torch.Size([89, 1, 5])
valX:   torch.Size([6, 5, 5])		valY:   torch.Size([6, 1, 5])
testX:   torch.Size([7, 5, 5])		testY:   torch.Size([7, 1, 5])
data loaded!
compiling model...
trainable parameters: 209,923
**** training model ****
2022-09-25 17:40:01 | epoch: 0001/50, training time: 0.8s, inference time: 0.0s
train loss: 207641382.8315, val_loss: 287895520.0000
val loss decrease from inf to 287895520.0000, saving model to ./output/test-hyper-parameter/batch_size/8/model.pkl
2022-09-25 17:40:02 | epoch: 0002/50, training time: 0.9s, inference time: 0.0s
train loss: 125965417.2135, val_loss: 179320880.0000
val loss decrease from 287895520.0000 to 179320880.0000, saving model to ./output/test-hyper-parameter/batch_size/8/model.pkl
2022-09-25 17:40:03 | epoch: 0003/50, training time: 0.8s, inference time: 0.0s
train loss: 118109876.6742, val_loss: 159103728.0000
val loss decrease from 179320880.0000 to 159103728.0000, saving model to ./output/test-hyper-parameter/batch_size/8/model.pkl
2022-09-25 17:40:04 | epoch: 0004/50, training time: 0.9s, inference time: 0.0s
train loss: 103031697.1685, val_loss: 155763168.0000
val loss decrease from 159103728.0000 to 155763168.0000, saving model to ./output/test-hyper-parameter/batch_size/8/model.pkl
2022-09-25 17:40:05 | epoch: 0005/50, training time: 1.0s, inference time: 0.0s
train loss: 91727126.5618, val_loss: 169259488.0000
2022-09-25 17:40:05 | epoch: 0006/50, training time: 0.8s, inference time: 0.0s
train loss: 87809883.9551, val_loss: 179694512.0000
2022-09-25 17:40:06 | epoch: 0007/50, training time: 0.7s, inference time: 0.0s
train loss: 93613264.0000, val_loss: 193144688.0000
2022-09-25 17:40:07 | epoch: 0008/50, training time: 0.7s, inference time: 0.0s
train loss: 82942726.6517, val_loss: 202632048.0000
2022-09-25 17:40:08 | epoch: 0009/50, training time: 0.7s, inference time: 0.0s
train loss: 89125834.3820, val_loss: 200817088.0000
2022-09-25 17:40:08 | epoch: 0010/50, training time: 0.7s, inference time: 0.0s
train loss: 85847604.4944, val_loss: 203444304.0000
2022-09-25 17:40:09 | epoch: 0011/50, training time: 0.9s, inference time: 0.0s
train loss: 78720622.7416, val_loss: 216903792.0000
2022-09-25 17:40:10 | epoch: 0012/50, training time: 0.8s, inference time: 0.0s
train loss: 75538789.7528, val_loss: 161129920.0000
2022-09-25 17:40:11 | epoch: 0013/50, training time: 0.8s, inference time: 0.0s
train loss: 71845923.7753, val_loss: 172838816.0000
2022-09-25 17:40:12 | epoch: 0014/50, training time: 0.7s, inference time: 0.0s
train loss: 75459635.2360, val_loss: 186343376.0000
2022-09-25 17:40:13 | epoch: 0015/50, training time: 0.9s, inference time: 0.0s
train loss: 63233773.6629, val_loss: 190148160.0000
2022-09-25 17:40:13 | epoch: 0016/50, training time: 0.8s, inference time: 0.0s
train loss: 62223604.6742, val_loss: 176178672.0000
2022-09-25 17:40:14 | epoch: 0017/50, training time: 0.9s, inference time: 0.0s
train loss: 67247425.3483, val_loss: 184753648.0000
2022-09-25 17:40:15 | epoch: 0018/50, training time: 0.9s, inference time: 0.0s
train loss: 64207020.3146, val_loss: 218318512.0000
2022-09-25 17:40:16 | epoch: 0019/50, training time: 0.8s, inference time: 0.0s
train loss: 57561283.2360, val_loss: 197658416.0000
2022-09-25 17:40:17 | epoch: 0020/50, training time: 0.8s, inference time: 0.0s
train loss: 64003602.3371, val_loss: 245497360.0000
2022-09-25 17:40:18 | epoch: 0021/50, training time: 0.9s, inference time: 0.0s
train loss: 57243460.5393, val_loss: 222699968.0000
2022-09-25 17:40:19 | epoch: 0022/50, training time: 0.8s, inference time: 0.0s
train loss: 52451748.4494, val_loss: 209326400.0000
2022-09-25 17:40:20 | epoch: 0023/50, training time: 0.9s, inference time: 0.0s
train loss: 52131368.0000, val_loss: 250474928.0000
2022-09-25 17:40:20 | epoch: 0024/50, training time: 0.9s, inference time: 0.0s
train loss: 47831537.5730, val_loss: 204966336.0000
2022-09-25 17:40:21 | epoch: 0025/50, training time: 0.8s, inference time: 0.0s
train loss: 49052115.6854, val_loss: 196966656.0000
2022-09-25 17:40:22 | epoch: 0026/50, training time: 0.7s, inference time: 0.0s
train loss: 52954641.0787, val_loss: 190436304.0000
2022-09-25 17:40:23 | epoch: 0027/50, training time: 0.8s, inference time: 0.0s
train loss: 49936353.0787, val_loss: 218935472.0000
2022-09-25 17:40:24 | epoch: 0028/50, training time: 0.8s, inference time: 0.0s
train loss: 53197352.8090, val_loss: 200430416.0000
2022-09-25 17:40:25 | epoch: 0029/50, training time: 0.8s, inference time: 0.0s
train loss: 46895528.5618, val_loss: 201534128.0000
2022-09-25 17:40:25 | epoch: 0030/50, training time: 0.9s, inference time: 0.0s
train loss: 48987297.4382, val_loss: 226325808.0000
2022-09-25 17:40:26 | epoch: 0031/50, training time: 0.7s, inference time: 0.0s
train loss: 49756456.6292, val_loss: 207304752.0000
2022-09-25 17:40:27 | epoch: 0032/50, training time: 0.8s, inference time: 0.0s
train loss: 52917480.9888, val_loss: 189120272.0000
2022-09-25 17:40:28 | epoch: 0033/50, training time: 0.7s, inference time: 0.0s
train loss: 46196375.7303, val_loss: 215810000.0000
2022-09-25 17:40:28 | epoch: 0034/50, training time: 0.7s, inference time: 0.0s
train loss: 43190827.8652, val_loss: 184034448.0000
2022-09-25 17:40:29 | epoch: 0035/50, training time: 0.7s, inference time: 0.0s
train loss: 45627874.3371, val_loss: 160497872.0000
2022-09-25 17:40:30 | epoch: 0036/50, training time: 0.7s, inference time: 0.0s
train loss: 36608631.7303, val_loss: 189500672.0000
2022-09-25 17:40:31 | epoch: 0037/50, training time: 0.8s, inference time: 0.0s
train loss: 46342975.7303, val_loss: 185613296.0000
2022-09-25 17:40:31 | epoch: 0038/50, training time: 0.8s, inference time: 0.0s
train loss: 36835996.9438, val_loss: 211898560.0000
2022-09-25 17:40:32 | epoch: 0039/50, training time: 0.7s, inference time: 0.0s
train loss: 34940953.6180, val_loss: 193124528.0000
2022-09-25 17:40:33 | epoch: 0040/50, training time: 0.8s, inference time: 0.0s
train loss: 41277108.4045, val_loss: 180079760.0000
2022-09-25 17:40:34 | epoch: 0041/50, training time: 0.8s, inference time: 0.0s
train loss: 32166123.8202, val_loss: 192580928.0000
2022-09-25 17:40:35 | epoch: 0042/50, training time: 0.8s, inference time: 0.0s
train loss: 34380653.0337, val_loss: 183082032.0000
2022-09-25 17:40:35 | epoch: 0043/50, training time: 0.7s, inference time: 0.0s
train loss: 29620485.7528, val_loss: 197420992.0000
2022-09-25 17:40:36 | epoch: 0044/50, training time: 0.8s, inference time: 0.0s
train loss: 35075790.2022, val_loss: 187932240.0000
2022-09-25 17:40:37 | epoch: 0045/50, training time: 0.7s, inference time: 0.0s
train loss: 32627846.0225, val_loss: 189232336.0000
2022-09-25 17:40:37 | epoch: 0046/50, training time: 0.7s, inference time: 0.0s
train loss: 33763724.2247, val_loss: 185808896.0000
2022-09-25 17:40:38 | epoch: 0047/50, training time: 0.7s, inference time: 0.0s
train loss: 33640417.2584, val_loss: 186801520.0000
2022-09-25 17:40:39 | epoch: 0048/50, training time: 0.8s, inference time: 0.0s
train loss: 35222025.5281, val_loss: 163978896.0000
2022-09-25 17:40:40 | epoch: 0049/50, training time: 0.7s, inference time: 0.0s
train loss: 39794715.8652, val_loss: 166039600.0000
2022-09-25 17:40:40 | epoch: 0050/50, training time: 0.7s, inference time: 0.0s
train loss: 28233073.3483, val_loss: 177493552.0000
Training and validation are completed, and model has been stored as ./output/test-hyper-parameter/batch_size/8/model.pkl
**** testing model ****
loading model from ./output/test-hyper-parameter/batch_size/8/model.pkl
model restored!
evaluating...
testing time: 0.0s
                MAE		RMSE		MAPE
train            4664.19		5926.68		9.33%
val              10081.68		13322.67		17.75%
test             9194.28		10708.87		16.40%
performance in each prediction step
step: 01         9194.28		10708.87		16.40%
average:         9194.28		10708.87		16.40%
total time: 0.7min
