K=8, L=1, SE_file='./data/train_data/basic/SE_data/group0/SE.txt', batch_size=16, d=8, decay_epoch=10, device='cpu', learning_rate=0.01, log_file='./output/test-hyper-parameter/learning_rate/0.01/log.txt', max_epoch=50, model_file='./output/test-hyper-parameter/learning_rate/0.01/model.pkl', num_his=5, num_pred=1, output_folder='./output/test-hyper-parameter/learning_rate/0.01', patience=100, test_ratio=0.1, time_slot=1440, traffic_file='./data/train_data/basic/train_data/mean_group0_dist3000.h5', train_ratio=0.8, val_ratio=0.1, view_batch_freq=100
main output folder./output/test-hyper-parameter/learning_rate/0.01
loading data...
trainX: torch.Size([89, 5, 5])		 trainY: torch.Size([89, 1, 5])
valX:   torch.Size([6, 5, 5])		valY:   torch.Size([6, 1, 5])
testX:   torch.Size([7, 5, 5])		testY:   torch.Size([7, 1, 5])
data loaded!
compiling model...
trainable parameters: 209,923
**** training model ****
2022-09-25 17:41:38 | epoch: 0001/50, training time: 0.4s, inference time: 0.0s
train loss: 205371208.8090, val_loss: 132551680.0000
val loss decrease from inf to 132551680.0000, saving model to ./output/test-hyper-parameter/learning_rate/0.01/model.pkl
2022-09-25 17:41:39 | epoch: 0002/50, training time: 0.4s, inference time: 0.0s
train loss: 115027545.7978, val_loss: 151899472.0000
2022-09-25 17:41:39 | epoch: 0003/50, training time: 0.4s, inference time: 0.0s
train loss: 96014590.9213, val_loss: 147186464.0000
2022-09-25 17:41:40 | epoch: 0004/50, training time: 0.5s, inference time: 0.0s
train loss: 87012708.4045, val_loss: 166030320.0000
2022-09-25 17:41:40 | epoch: 0005/50, training time: 0.5s, inference time: 0.0s
train loss: 79217838.7416, val_loss: 165159760.0000
2022-09-25 17:41:41 | epoch: 0006/50, training time: 0.5s, inference time: 0.0s
train loss: 71102519.1011, val_loss: 168825024.0000
2022-09-25 17:41:41 | epoch: 0007/50, training time: 0.5s, inference time: 0.0s
train loss: 62090065.7528, val_loss: 180186944.0000
2022-09-25 17:41:42 | epoch: 0008/50, training time: 0.6s, inference time: 0.0s
train loss: 57062243.8652, val_loss: 177254608.0000
2022-09-25 17:41:42 | epoch: 0009/50, training time: 0.5s, inference time: 0.0s
train loss: 55354533.4831, val_loss: 175527824.0000
2022-09-25 17:41:43 | epoch: 0010/50, training time: 0.5s, inference time: 0.0s
train loss: 54057864.9888, val_loss: 182918384.0000
2022-09-25 17:41:43 | epoch: 0011/50, training time: 0.5s, inference time: 0.0s
train loss: 49806042.4270, val_loss: 189204656.0000
2022-09-25 17:41:44 | epoch: 0012/50, training time: 0.4s, inference time: 0.0s
train loss: 45623738.5618, val_loss: 175546224.0000
2022-09-25 17:41:44 | epoch: 0013/50, training time: 0.4s, inference time: 0.0s
train loss: 41633024.1348, val_loss: 171755344.0000
2022-09-25 17:41:44 | epoch: 0014/50, training time: 0.4s, inference time: 0.0s
train loss: 43725603.4157, val_loss: 151951328.0000
2022-09-25 17:41:45 | epoch: 0015/50, training time: 0.4s, inference time: 0.0s
train loss: 44952499.6854, val_loss: 141634704.0000
2022-09-25 17:41:45 | epoch: 0016/50, training time: 0.4s, inference time: 0.0s
train loss: 41826830.7416, val_loss: 159929056.0000
2022-09-25 17:41:46 | epoch: 0017/50, training time: 0.4s, inference time: 0.0s
train loss: 38483762.4270, val_loss: 156876944.0000
2022-09-25 17:41:46 | epoch: 0018/50, training time: 0.4s, inference time: 0.0s
train loss: 32351855.6180, val_loss: 161903968.0000
2022-09-25 17:41:47 | epoch: 0019/50, training time: 0.5s, inference time: 0.0s
train loss: 29210232.6517, val_loss: 152931344.0000
2022-09-25 17:41:47 | epoch: 0020/50, training time: 0.4s, inference time: 0.0s
train loss: 31258018.2472, val_loss: 150743072.0000
2022-09-25 17:41:48 | epoch: 0021/50, training time: 0.4s, inference time: 0.0s
train loss: 26384474.9663, val_loss: 109473512.0000
val loss decrease from 132551680.0000 to 109473512.0000, saving model to ./output/test-hyper-parameter/learning_rate/0.01/model.pkl
2022-09-25 17:41:48 | epoch: 0022/50, training time: 0.5s, inference time: 0.0s
train loss: 20485484.5393, val_loss: 99138840.0000
val loss decrease from 109473512.0000 to 99138840.0000, saving model to ./output/test-hyper-parameter/learning_rate/0.01/model.pkl
2022-09-25 17:41:49 | epoch: 0023/50, training time: 0.4s, inference time: 0.0s
train loss: 23179047.5281, val_loss: 107645952.0000
2022-09-25 17:41:49 | epoch: 0024/50, training time: 0.5s, inference time: 0.0s
train loss: 19901231.7303, val_loss: 111543832.0000
2022-09-25 17:41:49 | epoch: 0025/50, training time: 0.4s, inference time: 0.0s
train loss: 21655435.2360, val_loss: 98582568.0000
val loss decrease from 99138840.0000 to 98582568.0000, saving model to ./output/test-hyper-parameter/learning_rate/0.01/model.pkl
2022-09-25 17:41:50 | epoch: 0026/50, training time: 0.4s, inference time: 0.0s
train loss: 21346405.8427, val_loss: 98927136.0000
2022-09-25 17:41:50 | epoch: 0027/50, training time: 0.4s, inference time: 0.0s
train loss: 15998770.4494, val_loss: 111004672.0000
2022-09-25 17:41:51 | epoch: 0028/50, training time: 0.4s, inference time: 0.0s
train loss: 16843689.8652, val_loss: 123916576.0000
2022-09-25 17:41:51 | epoch: 0029/50, training time: 0.4s, inference time: 0.0s
train loss: 13328494.8876, val_loss: 125891328.0000
2022-09-25 17:41:52 | epoch: 0030/50, training time: 0.4s, inference time: 0.0s
train loss: 15079401.9326, val_loss: 119154808.0000
2022-09-25 17:41:52 | epoch: 0031/50, training time: 0.4s, inference time: 0.0s
train loss: 13840264.6292, val_loss: 116469544.0000
2022-09-25 17:41:53 | epoch: 0032/50, training time: 0.4s, inference time: 0.0s
train loss: 15789523.7079, val_loss: 118575008.0000
2022-09-25 17:41:53 | epoch: 0033/50, training time: 0.4s, inference time: 0.0s
train loss: 14074901.3933, val_loss: 138302912.0000
2022-09-25 17:41:53 | epoch: 0034/50, training time: 0.4s, inference time: 0.0s
train loss: 16492346.8989, val_loss: 133802976.0000
2022-09-25 17:41:54 | epoch: 0035/50, training time: 0.4s, inference time: 0.0s
train loss: 16032898.0225, val_loss: 138729360.0000
2022-09-25 17:41:54 | epoch: 0036/50, training time: 0.4s, inference time: 0.0s
train loss: 17781227.5506, val_loss: 164400464.0000
2022-09-25 17:41:55 | epoch: 0037/50, training time: 0.4s, inference time: 0.0s
train loss: 18082249.4831, val_loss: 147763472.0000
2022-09-25 17:41:55 | epoch: 0038/50, training time: 0.4s, inference time: 0.0s
train loss: 13757311.2921, val_loss: 149061424.0000
2022-09-25 17:41:56 | epoch: 0039/50, training time: 0.4s, inference time: 0.0s
train loss: 12789161.5730, val_loss: 150754224.0000
2022-09-25 17:41:56 | epoch: 0040/50, training time: 0.4s, inference time: 0.0s
train loss: 13347075.9775, val_loss: 128335960.0000
2022-09-25 17:41:57 | epoch: 0041/50, training time: 0.4s, inference time: 0.0s
train loss: 9875825.3933, val_loss: 119672216.0000
2022-09-25 17:41:57 | epoch: 0042/50, training time: 0.4s, inference time: 0.0s
train loss: 12902847.4045, val_loss: 135211232.0000
2022-09-25 17:41:57 | epoch: 0043/50, training time: 0.4s, inference time: 0.0s
train loss: 11964218.0225, val_loss: 137350880.0000
2022-09-25 17:41:58 | epoch: 0044/50, training time: 0.4s, inference time: 0.0s
train loss: 8726783.4045, val_loss: 127914600.0000
2022-09-25 17:41:58 | epoch: 0045/50, training time: 0.4s, inference time: 0.0s
train loss: 10051624.9101, val_loss: 139491280.0000
2022-09-25 17:41:59 | epoch: 0046/50, training time: 0.4s, inference time: 0.0s
train loss: 9363174.9438, val_loss: 138070384.0000
2022-09-25 17:41:59 | epoch: 0047/50, training time: 0.4s, inference time: 0.0s
train loss: 8690181.0899, val_loss: 137281792.0000
2022-09-25 17:42:00 | epoch: 0048/50, training time: 0.4s, inference time: 0.0s
train loss: 12273541.1461, val_loss: 145733136.0000
2022-09-25 17:42:00 | epoch: 0049/50, training time: 0.4s, inference time: 0.0s
train loss: 14212653.8427, val_loss: 144603728.0000
2022-09-25 17:42:01 | epoch: 0050/50, training time: 0.5s, inference time: 0.0s
train loss: 10840245.0000, val_loss: 155018128.0000
Training and validation are completed, and model has been stored as ./output/test-hyper-parameter/learning_rate/0.01/model.pkl
**** testing model ****
loading model from ./output/test-hyper-parameter/learning_rate/0.01/model.pkl
model restored!
evaluating...
testing time: 0.0s
                MAE		RMSE		MAPE
train            1983.50		2545.83		3.85%
val              9727.50		12450.63		16.68%
test             9443.20		11245.88		16.18%
performance in each prediction step
step: 01         9443.20		11245.88		16.18%
average:         9443.20		11245.88		16.18%
total time: 0.4min
