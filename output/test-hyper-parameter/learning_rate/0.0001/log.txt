K=8, L=1, SE_file='./data/train_data/basic/SE_data/group0/SE.txt', batch_size=16, d=8, decay_epoch=10, device='cpu', learning_rate=0.0001, log_file='./output/test-hyper-parameter/learning_rate/0.0001/log.txt', max_epoch=50, model_file='./output/test-hyper-parameter/learning_rate/0.0001/model.pkl', num_his=5, num_pred=1, output_folder='./output/test-hyper-parameter/learning_rate/0.0001', patience=100, test_ratio=0.1, time_slot=1440, traffic_file='./data/train_data/basic/train_data/mean_group0_dist3000.h5', train_ratio=0.8, val_ratio=0.1, view_batch_freq=100
main output folder./output/test-hyper-parameter/learning_rate/0.0001
loading data...
trainX: torch.Size([89, 5, 5])		 trainY: torch.Size([89, 1, 5])
valX:   torch.Size([6, 5, 5])		valY:   torch.Size([6, 1, 5])
testX:   torch.Size([7, 5, 5])		testY:   torch.Size([7, 1, 5])
data loaded!
compiling model...
trainable parameters: 209,923
**** training model ****
2022-09-25 17:42:33 | epoch: 0001/50, training time: 0.4s, inference time: 0.0s
train loss: 407661634.6966, val_loss: 309522208.0000
val loss decrease from inf to 309522208.0000, saving model to ./output/test-hyper-parameter/learning_rate/0.0001/model.pkl
2022-09-25 17:42:33 | epoch: 0002/50, training time: 0.4s, inference time: 0.0s
train loss: 333420290.1573, val_loss: 294006368.0000
val loss decrease from 309522208.0000 to 294006368.0000, saving model to ./output/test-hyper-parameter/learning_rate/0.0001/model.pkl
2022-09-25 17:42:34 | epoch: 0003/50, training time: 0.5s, inference time: 0.0s
train loss: 271838390.1124, val_loss: 242953808.0000
val loss decrease from 294006368.0000 to 242953808.0000, saving model to ./output/test-hyper-parameter/learning_rate/0.0001/model.pkl
2022-09-25 17:42:34 | epoch: 0004/50, training time: 0.4s, inference time: 0.0s
train loss: 212269112.6292, val_loss: 237328496.0000
val loss decrease from 242953808.0000 to 237328496.0000, saving model to ./output/test-hyper-parameter/learning_rate/0.0001/model.pkl
2022-09-25 17:42:35 | epoch: 0005/50, training time: 0.4s, inference time: 0.0s
train loss: 194299408.8989, val_loss: 269063104.0000
2022-09-25 17:42:35 | epoch: 0006/50, training time: 0.5s, inference time: 0.0s
train loss: 168651085.3034, val_loss: 307638048.0000
2022-09-25 17:42:36 | epoch: 0007/50, training time: 0.5s, inference time: 0.0s
train loss: 140732063.3708, val_loss: 351130432.0000
2022-09-25 17:42:36 | epoch: 0008/50, training time: 0.5s, inference time: 0.0s
train loss: 130522696.1798, val_loss: 367641248.0000
2022-09-25 17:42:37 | epoch: 0009/50, training time: 0.5s, inference time: 0.0s
train loss: 135221817.5281, val_loss: 274135584.0000
2022-09-25 17:42:37 | epoch: 0010/50, training time: 0.5s, inference time: 0.0s
train loss: 118080254.0225, val_loss: 189918608.0000
val loss decrease from 237328496.0000 to 189918608.0000, saving model to ./output/test-hyper-parameter/learning_rate/0.0001/model.pkl
2022-09-25 17:42:38 | epoch: 0011/50, training time: 0.5s, inference time: 0.0s
train loss: 116338291.2360, val_loss: 178602576.0000
val loss decrease from 189918608.0000 to 178602576.0000, saving model to ./output/test-hyper-parameter/learning_rate/0.0001/model.pkl
2022-09-25 17:42:38 | epoch: 0012/50, training time: 0.4s, inference time: 0.0s
train loss: 104362646.4719, val_loss: 197710064.0000
2022-09-25 17:42:39 | epoch: 0013/50, training time: 0.4s, inference time: 0.0s
train loss: 106582326.2921, val_loss: 205239440.0000
2022-09-25 17:42:39 | epoch: 0014/50, training time: 0.4s, inference time: 0.0s
train loss: 101621472.0000, val_loss: 207494384.0000
2022-09-25 17:42:40 | epoch: 0015/50, training time: 0.4s, inference time: 0.0s
train loss: 94922608.7191, val_loss: 199400752.0000
2022-09-25 17:42:40 | epoch: 0016/50, training time: 0.5s, inference time: 0.0s
train loss: 93482886.0225, val_loss: 194625840.0000
2022-09-25 17:42:41 | epoch: 0017/50, training time: 0.5s, inference time: 0.0s
train loss: 94037930.6067, val_loss: 190918192.0000
2022-09-25 17:42:41 | epoch: 0018/50, training time: 0.6s, inference time: 0.0s
train loss: 96146971.5056, val_loss: 187757008.0000
2022-09-25 17:42:42 | epoch: 0019/50, training time: 0.6s, inference time: 0.0s
train loss: 89236703.5506, val_loss: 184305088.0000
2022-09-25 17:42:42 | epoch: 0020/50, training time: 0.5s, inference time: 0.0s
train loss: 81452903.1910, val_loss: 188645376.0000
2022-09-25 17:42:43 | epoch: 0021/50, training time: 0.5s, inference time: 0.0s
train loss: 77460902.9213, val_loss: 181438912.0000
2022-09-25 17:42:43 | epoch: 0022/50, training time: 0.6s, inference time: 0.0s
train loss: 82465685.6629, val_loss: 187995328.0000
2022-09-25 17:42:44 | epoch: 0023/50, training time: 0.5s, inference time: 0.0s
train loss: 72218629.7528, val_loss: 185402160.0000
2022-09-25 17:42:44 | epoch: 0024/50, training time: 0.5s, inference time: 0.0s
train loss: 71868180.2697, val_loss: 185598736.0000
2022-09-25 17:42:45 | epoch: 0025/50, training time: 0.5s, inference time: 0.0s
train loss: 71589763.3708, val_loss: 187684688.0000
2022-09-25 17:42:46 | epoch: 0026/50, training time: 0.6s, inference time: 0.0s
train loss: 77817564.3596, val_loss: 183039296.0000
2022-09-25 17:42:46 | epoch: 0027/50, training time: 0.5s, inference time: 0.0s
train loss: 68972834.4270, val_loss: 167774016.0000
val loss decrease from 178602576.0000 to 167774016.0000, saving model to ./output/test-hyper-parameter/learning_rate/0.0001/model.pkl
2022-09-25 17:42:47 | epoch: 0028/50, training time: 0.5s, inference time: 0.0s
train loss: 69490000.5393, val_loss: 173621680.0000
2022-09-25 17:42:47 | epoch: 0029/50, training time: 0.5s, inference time: 0.0s
train loss: 68806082.4270, val_loss: 171725920.0000
2022-09-25 17:42:48 | epoch: 0030/50, training time: 0.4s, inference time: 0.0s
train loss: 71380713.5281, val_loss: 170311216.0000
2022-09-25 17:42:48 | epoch: 0031/50, training time: 0.4s, inference time: 0.0s
train loss: 72418690.0674, val_loss: 168052624.0000
2022-09-25 17:42:48 | epoch: 0032/50, training time: 0.4s, inference time: 0.0s
train loss: 62737607.6404, val_loss: 171906768.0000
2022-09-25 17:42:49 | epoch: 0033/50, training time: 0.4s, inference time: 0.0s
train loss: 57935979.1461, val_loss: 165562512.0000
val loss decrease from 167774016.0000 to 165562512.0000, saving model to ./output/test-hyper-parameter/learning_rate/0.0001/model.pkl
2022-09-25 17:42:49 | epoch: 0034/50, training time: 0.4s, inference time: 0.0s
train loss: 65691967.1910, val_loss: 166162464.0000
2022-09-25 17:42:50 | epoch: 0035/50, training time: 0.4s, inference time: 0.0s
train loss: 61029791.8202, val_loss: 166751952.0000
2022-09-25 17:42:50 | epoch: 0036/50, training time: 0.4s, inference time: 0.0s
train loss: 66898147.8652, val_loss: 165477392.0000
val loss decrease from 165562512.0000 to 165477392.0000, saving model to ./output/test-hyper-parameter/learning_rate/0.0001/model.pkl
2022-09-25 17:42:51 | epoch: 0037/50, training time: 0.4s, inference time: 0.0s
train loss: 57544898.2472, val_loss: 164359984.0000
val loss decrease from 165477392.0000 to 164359984.0000, saving model to ./output/test-hyper-parameter/learning_rate/0.0001/model.pkl
2022-09-25 17:42:51 | epoch: 0038/50, training time: 0.4s, inference time: 0.0s
train loss: 67323714.0674, val_loss: 163165488.0000
val loss decrease from 164359984.0000 to 163165488.0000, saving model to ./output/test-hyper-parameter/learning_rate/0.0001/model.pkl
2022-09-25 17:42:52 | epoch: 0039/50, training time: 0.4s, inference time: 0.0s
train loss: 69066254.2022, val_loss: 166705872.0000
2022-09-25 17:42:52 | epoch: 0040/50, training time: 0.4s, inference time: 0.0s
train loss: 52371420.8539, val_loss: 164042032.0000
2022-09-25 17:42:52 | epoch: 0041/50, training time: 0.4s, inference time: 0.0s
train loss: 57415891.1011, val_loss: 163560720.0000
2022-09-25 17:42:53 | epoch: 0042/50, training time: 0.4s, inference time: 0.0s
train loss: 52697692.8539, val_loss: 168304112.0000
2022-09-25 17:42:53 | epoch: 0043/50, training time: 0.4s, inference time: 0.0s
train loss: 58550236.8539, val_loss: 169139552.0000
2022-09-25 17:42:54 | epoch: 0044/50, training time: 0.4s, inference time: 0.0s
train loss: 48871819.9101, val_loss: 167076048.0000
2022-09-25 17:42:54 | epoch: 0045/50, training time: 0.4s, inference time: 0.0s
train loss: 51252302.8315, val_loss: 170095776.0000
2022-09-25 17:42:55 | epoch: 0046/50, training time: 0.4s, inference time: 0.0s
train loss: 50160585.2584, val_loss: 174648480.0000
2022-09-25 17:42:55 | epoch: 0047/50, training time: 0.4s, inference time: 0.0s
train loss: 51221310.6067, val_loss: 172644688.0000
2022-09-25 17:42:56 | epoch: 0048/50, training time: 0.4s, inference time: 0.0s
train loss: 54570944.9888, val_loss: 173785248.0000
2022-09-25 17:42:56 | epoch: 0049/50, training time: 0.4s, inference time: 0.0s
train loss: 56794633.8876, val_loss: 167746256.0000
2022-09-25 17:42:57 | epoch: 0050/50, training time: 0.4s, inference time: 0.0s
train loss: 52080791.4607, val_loss: 168347072.0000
Training and validation are completed, and model has been stored as ./output/test-hyper-parameter/learning_rate/0.0001/model.pkl
**** testing model ****
loading model from ./output/test-hyper-parameter/learning_rate/0.0001/model.pkl
model restored!
evaluating...
testing time: 0.0s
                MAE		RMSE		MAPE
train            5341.15		6820.42		10.03%
val              10045.01		12974.86		16.14%
test             9661.56		11442.90		17.12%
performance in each prediction step
step: 01         9661.56		11442.90		17.12%
average:         9661.56		11442.90		17.12%
total time: 0.4min
