K=8, L=1, SE_file='./data/train_data/basic/SE_data/group0/SE.txt', batch_size=16, d=8, decay_epoch=10, device='cpu', learning_rate=0.001, log_file='./output/test-hyper-parameter(price)/learning_rate/0.001/log.txt', max_epoch=50, model_file='./output/test-hyper-parameter(price)/learning_rate/0.001/model.pkl', num_his=3, num_pred=1, output_folder='./output/test-hyper-parameter(price)/learning_rate/0.001', patience=100, test_ratio=0.1, time_slot=1440, traffic_file='./data/train_data/basic/train_data/mean_group0_dist3000.h5', train_ratio=0.8, val_ratio=0.1, view_batch_freq=100
main output folder./output/test-hyper-parameter(price)/learning_rate/0.001
loading data...
trainX: torch.Size([91, 3, 5])		 trainY: torch.Size([91, 1, 5])
valX:   torch.Size([8, 3, 5])		valY:   torch.Size([8, 1, 5])
testX:   torch.Size([9, 3, 5])		testY:   torch.Size([9, 1, 5])
data loaded!
compiling model...
trainable parameters: 209,923
**** training model ****
2022-09-26 19:48:09 | epoch: 0001/50, training time: 0.7s, inference time: 0.0s
train loss: 243618417.6703, val_loss: 223178800.0000
val loss decrease from inf to 223178800.0000, saving model to ./output/test-hyper-parameter(price)/learning_rate/0.001/model.pkl
2022-09-26 19:48:09 | epoch: 0002/50, training time: 0.6s, inference time: 0.0s
train loss: 121746957.6264, val_loss: 212464864.0000
val loss decrease from 223178800.0000 to 212464864.0000, saving model to ./output/test-hyper-parameter(price)/learning_rate/0.001/model.pkl
2022-09-26 19:48:10 | epoch: 0003/50, training time: 0.7s, inference time: 0.0s
train loss: 111819205.8901, val_loss: 182990352.0000
val loss decrease from 212464864.0000 to 182990352.0000, saving model to ./output/test-hyper-parameter(price)/learning_rate/0.001/model.pkl
2022-09-26 19:48:11 | epoch: 0004/50, training time: 0.8s, inference time: 0.0s
train loss: 98666098.2857, val_loss: 152880896.0000
val loss decrease from 182990352.0000 to 152880896.0000, saving model to ./output/test-hyper-parameter(price)/learning_rate/0.001/model.pkl
2022-09-26 19:48:12 | epoch: 0005/50, training time: 0.7s, inference time: 0.0s
train loss: 87066617.3187, val_loss: 148869520.0000
val loss decrease from 152880896.0000 to 148869520.0000, saving model to ./output/test-hyper-parameter(price)/learning_rate/0.001/model.pkl
2022-09-26 19:48:12 | epoch: 0006/50, training time: 0.5s, inference time: 0.0s
train loss: 80421283.9560, val_loss: 134596672.0000
val loss decrease from 148869520.0000 to 134596672.0000, saving model to ./output/test-hyper-parameter(price)/learning_rate/0.001/model.pkl
2022-09-26 19:48:13 | epoch: 0007/50, training time: 0.6s, inference time: 0.0s
train loss: 67605917.1868, val_loss: 119781232.0000
val loss decrease from 134596672.0000 to 119781232.0000, saving model to ./output/test-hyper-parameter(price)/learning_rate/0.001/model.pkl
2022-09-26 19:48:13 | epoch: 0008/50, training time: 0.6s, inference time: 0.0s
train loss: 64059002.2857, val_loss: 126167088.0000
2022-09-26 19:48:14 | epoch: 0009/50, training time: 0.5s, inference time: 0.0s
train loss: 58046533.1868, val_loss: 138443232.0000
2022-09-26 19:48:14 | epoch: 0010/50, training time: 0.4s, inference time: 0.0s
train loss: 44004000.1319, val_loss: 156636288.0000
2022-09-26 19:48:15 | epoch: 0011/50, training time: 0.5s, inference time: 0.0s
train loss: 43820408.9231, val_loss: 175492192.0000
2022-09-26 19:48:15 | epoch: 0012/50, training time: 0.5s, inference time: 0.0s
train loss: 46823166.6374, val_loss: 202835984.0000
2022-09-26 19:48:16 | epoch: 0013/50, training time: 0.5s, inference time: 0.0s
train loss: 42527887.7802, val_loss: 203316736.0000
2022-09-26 19:48:16 | epoch: 0014/50, training time: 0.4s, inference time: 0.0s
train loss: 41625739.7363, val_loss: 183874400.0000
2022-09-26 19:48:17 | epoch: 0015/50, training time: 0.5s, inference time: 0.0s
train loss: 33576899.0330, val_loss: 183050144.0000
2022-09-26 19:48:17 | epoch: 0016/50, training time: 0.5s, inference time: 0.0s
train loss: 31599625.3626, val_loss: 183933168.0000
2022-09-26 19:48:18 | epoch: 0017/50, training time: 0.5s, inference time: 0.0s
train loss: 36513698.8132, val_loss: 188267632.0000
2022-09-26 19:48:18 | epoch: 0018/50, training time: 0.4s, inference time: 0.0s
train loss: 28710350.4176, val_loss: 174281200.0000
2022-09-26 19:48:19 | epoch: 0019/50, training time: 0.4s, inference time: 0.0s
train loss: 38374898.7692, val_loss: 156510544.0000
2022-09-26 19:48:19 | epoch: 0020/50, training time: 0.4s, inference time: 0.0s
train loss: 35628410.1099, val_loss: 153823136.0000
2022-09-26 19:48:20 | epoch: 0021/50, training time: 0.4s, inference time: 0.0s
train loss: 29136336.9670, val_loss: 178459680.0000
2022-09-26 19:48:20 | epoch: 0022/50, training time: 0.4s, inference time: 0.0s
train loss: 32637747.9560, val_loss: 193816112.0000
2022-09-26 19:48:21 | epoch: 0023/50, training time: 0.4s, inference time: 0.0s
train loss: 27463018.8132, val_loss: 191612064.0000
2022-09-26 19:48:21 | epoch: 0024/50, training time: 0.5s, inference time: 0.0s
train loss: 29291244.8352, val_loss: 174478880.0000
2022-09-26 19:48:21 | epoch: 0025/50, training time: 0.4s, inference time: 0.0s
train loss: 26171961.0989, val_loss: 172638784.0000
2022-09-26 19:48:22 | epoch: 0026/50, training time: 0.4s, inference time: 0.0s
train loss: 21452521.1429, val_loss: 173025184.0000
2022-09-26 19:48:22 | epoch: 0027/50, training time: 0.5s, inference time: 0.0s
train loss: 29415956.2637, val_loss: 178987552.0000
2022-09-26 19:48:23 | epoch: 0028/50, training time: 0.5s, inference time: 0.0s
train loss: 25248401.2527, val_loss: 186540784.0000
2022-09-26 19:48:24 | epoch: 0029/50, training time: 0.8s, inference time: 0.0s
train loss: 19272143.5604, val_loss: 214410784.0000
2022-09-26 19:48:25 | epoch: 0030/50, training time: 0.8s, inference time: 0.0s
train loss: 21325443.0330, val_loss: 206913184.0000
2022-09-26 19:48:25 | epoch: 0031/50, training time: 0.8s, inference time: 0.0s
train loss: 28096967.9560, val_loss: 187873824.0000
2022-09-26 19:48:26 | epoch: 0032/50, training time: 0.8s, inference time: 0.0s
train loss: 19840605.5604, val_loss: 178495056.0000
2022-09-26 19:48:27 | epoch: 0033/50, training time: 0.8s, inference time: 0.0s
train loss: 23344128.3077, val_loss: 179424864.0000
2022-09-26 19:48:28 | epoch: 0034/50, training time: 0.8s, inference time: 0.0s
train loss: 19371526.4615, val_loss: 182235184.0000
2022-09-26 19:48:29 | epoch: 0035/50, training time: 0.8s, inference time: 0.0s
train loss: 24084804.3077, val_loss: 192182768.0000
2022-09-26 19:48:29 | epoch: 0036/50, training time: 0.8s, inference time: 0.0s
train loss: 24413131.2308, val_loss: 173922688.0000
2022-09-26 19:48:30 | epoch: 0037/50, training time: 0.8s, inference time: 0.0s
train loss: 19631017.6264, val_loss: 182325472.0000
2022-09-26 19:48:31 | epoch: 0038/50, training time: 0.8s, inference time: 0.0s
train loss: 23462268.2857, val_loss: 185387776.0000
2022-09-26 19:48:32 | epoch: 0039/50, training time: 0.8s, inference time: 0.0s
train loss: 22818450.7692, val_loss: 181649024.0000
2022-09-26 19:48:33 | epoch: 0040/50, training time: 0.8s, inference time: 0.0s
train loss: 28131604.5714, val_loss: 178486288.0000
2022-09-26 19:48:33 | epoch: 0041/50, training time: 0.8s, inference time: 0.0s
train loss: 19748888.2418, val_loss: 176605088.0000
2022-09-26 19:48:34 | epoch: 0042/50, training time: 0.8s, inference time: 0.0s
train loss: 17022837.4286, val_loss: 184008848.0000
2022-09-26 19:48:35 | epoch: 0043/50, training time: 0.7s, inference time: 0.0s
train loss: 22691509.1209, val_loss: 187817504.0000
2022-09-26 19:48:36 | epoch: 0044/50, training time: 0.8s, inference time: 0.0s
train loss: 17890686.4615, val_loss: 196909088.0000
2022-09-26 19:48:37 | epoch: 0045/50, training time: 0.8s, inference time: 0.0s
train loss: 17124085.3846, val_loss: 189986096.0000
2022-09-26 19:48:37 | epoch: 0046/50, training time: 0.8s, inference time: 0.0s
train loss: 15614126.3626, val_loss: 186957088.0000
2022-09-26 19:48:38 | epoch: 0047/50, training time: 0.8s, inference time: 0.0s
train loss: 16934010.2857, val_loss: 184480560.0000
2022-09-26 19:48:39 | epoch: 0048/50, training time: 0.8s, inference time: 0.0s
train loss: 15584875.8901, val_loss: 191757584.0000
2022-09-26 19:48:40 | epoch: 0049/50, training time: 0.7s, inference time: 0.0s
train loss: 20325485.9780, val_loss: 181877472.0000
2022-09-26 19:48:41 | epoch: 0050/50, training time: 0.8s, inference time: 0.0s
train loss: 18363266.8791, val_loss: 171387520.0000
Training and validation are completed, and model has been stored as ./output/test-hyper-parameter(price)/learning_rate/0.001/model.pkl
**** testing model ****
loading model from ./output/test-hyper-parameter(price)/learning_rate/0.001/model.pkl
model restored!
evaluating...
testing time: 0.0s
                MAE		RMSE		MAPE
train            2904.61		3607.70		5.30%
val              10421.24		13091.51		17.82%
test             9153.86		11275.60		15.37%
performance in each prediction step
step: 01         9153.86		11275.60		15.37%
average:         9153.86		11275.60		15.37%
total time: 0.6min
