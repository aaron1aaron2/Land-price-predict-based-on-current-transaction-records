K=8, L=1, SE_file='./data/train_data/basic/SE_data/group0/SE.txt', batch_size=16, d=8, decay_epoch=10, device='cpu', learning_rate=0.01, log_file='./output/test-hyper-parameter(price)/learning_rate/0.01/log.txt', max_epoch=50, model_file='./output/test-hyper-parameter(price)/learning_rate/0.01/model.pkl', num_his=3, num_pred=1, output_folder='./output/test-hyper-parameter(price)/learning_rate/0.01', patience=100, test_ratio=0.1, time_slot=1440, traffic_file='./data/train_data/basic/train_data/mean_group0_dist3000.h5', train_ratio=0.8, val_ratio=0.1, view_batch_freq=100
main output folder./output/test-hyper-parameter(price)/learning_rate/0.01
loading data...
trainX: torch.Size([91, 3, 5])		 trainY: torch.Size([91, 1, 5])
valX:   torch.Size([8, 3, 5])		valY:   torch.Size([8, 1, 5])
testX:   torch.Size([9, 3, 5])		testY:   torch.Size([9, 1, 5])
data loaded!
compiling model...
trainable parameters: 209,923
**** training model ****
2022-09-26 19:47:25 | epoch: 0001/50, training time: 0.6s, inference time: 0.0s
train loss: 216966355.8681, val_loss: 127065600.0000
val loss decrease from inf to 127065600.0000, saving model to ./output/test-hyper-parameter(price)/learning_rate/0.01/model.pkl
2022-09-26 19:47:25 | epoch: 0002/50, training time: 0.5s, inference time: 0.0s
train loss: 119642054.6813, val_loss: 118616112.0000
val loss decrease from 127065600.0000 to 118616112.0000, saving model to ./output/test-hyper-parameter(price)/learning_rate/0.01/model.pkl
2022-09-26 19:47:26 | epoch: 0003/50, training time: 0.6s, inference time: 0.0s
train loss: 98450580.5714, val_loss: 128815272.0000
2022-09-26 19:47:27 | epoch: 0004/50, training time: 0.6s, inference time: 0.0s
train loss: 91206958.2857, val_loss: 142531488.0000
2022-09-26 19:47:27 | epoch: 0005/50, training time: 0.5s, inference time: 0.0s
train loss: 74049434.6374, val_loss: 157442672.0000
2022-09-26 19:47:28 | epoch: 0006/50, training time: 0.7s, inference time: 0.0s
train loss: 73088605.0989, val_loss: 135175504.0000
2022-09-26 19:47:29 | epoch: 0007/50, training time: 0.8s, inference time: 0.0s
train loss: 64181221.8901, val_loss: 132984112.0000
2022-09-26 19:47:30 | epoch: 0008/50, training time: 0.8s, inference time: 0.0s
train loss: 58200598.3297, val_loss: 122080528.0000
2022-09-26 19:47:30 | epoch: 0009/50, training time: 0.8s, inference time: 0.0s
train loss: 56379486.6374, val_loss: 115382952.0000
val loss decrease from 118616112.0000 to 115382952.0000, saving model to ./output/test-hyper-parameter(price)/learning_rate/0.01/model.pkl
2022-09-26 19:47:31 | epoch: 0010/50, training time: 0.8s, inference time: 0.0s
train loss: 57611574.1099, val_loss: 125811760.0000
2022-09-26 19:47:32 | epoch: 0011/50, training time: 0.7s, inference time: 0.0s
train loss: 52111711.0330, val_loss: 115536360.0000
2022-09-26 19:47:33 | epoch: 0012/50, training time: 0.7s, inference time: 0.0s
train loss: 41981250.5055, val_loss: 142313696.0000
2022-09-26 19:47:34 | epoch: 0013/50, training time: 0.8s, inference time: 0.0s
train loss: 39519660.6593, val_loss: 125895144.0000
2022-09-26 19:47:34 | epoch: 0014/50, training time: 0.8s, inference time: 0.0s
train loss: 43513069.2308, val_loss: 114516376.0000
val loss decrease from 115382952.0000 to 114516376.0000, saving model to ./output/test-hyper-parameter(price)/learning_rate/0.01/model.pkl
2022-09-26 19:47:35 | epoch: 0015/50, training time: 0.7s, inference time: 0.0s
train loss: 39741884.4835, val_loss: 111382208.0000
val loss decrease from 114516376.0000 to 111382208.0000, saving model to ./output/test-hyper-parameter(price)/learning_rate/0.01/model.pkl
2022-09-26 19:47:36 | epoch: 0016/50, training time: 0.8s, inference time: 0.0s
train loss: 33321096.2198, val_loss: 129357144.0000
2022-09-26 19:47:37 | epoch: 0017/50, training time: 0.7s, inference time: 0.0s
train loss: 33846121.1868, val_loss: 115820904.0000
2022-09-26 19:47:38 | epoch: 0018/50, training time: 0.7s, inference time: 0.0s
train loss: 37130690.2418, val_loss: 117831896.0000
2022-09-26 19:47:38 | epoch: 0019/50, training time: 0.8s, inference time: 0.0s
train loss: 27063450.4396, val_loss: 134203696.0000
2022-09-26 19:47:39 | epoch: 0020/50, training time: 0.7s, inference time: 0.0s
train loss: 39479973.0549, val_loss: 128775016.0000
2022-09-26 19:47:40 | epoch: 0021/50, training time: 0.8s, inference time: 0.0s
train loss: 27798487.3187, val_loss: 131142576.0000
2022-09-26 19:47:41 | epoch: 0022/50, training time: 0.7s, inference time: 0.0s
train loss: 24306652.8791, val_loss: 139162384.0000
2022-09-26 19:47:42 | epoch: 0023/50, training time: 0.8s, inference time: 0.0s
train loss: 22653736.2747, val_loss: 102464216.0000
val loss decrease from 111382208.0000 to 102464216.0000, saving model to ./output/test-hyper-parameter(price)/learning_rate/0.01/model.pkl
2022-09-26 19:47:42 | epoch: 0024/50, training time: 0.8s, inference time: 0.0s
train loss: 24959005.2747, val_loss: 120264752.0000
2022-09-26 19:47:43 | epoch: 0025/50, training time: 0.7s, inference time: 0.0s
train loss: 21930570.4396, val_loss: 119020352.0000
2022-09-26 19:47:44 | epoch: 0026/50, training time: 0.8s, inference time: 0.0s
train loss: 16895559.7033, val_loss: 120766384.0000
2022-09-26 19:47:45 | epoch: 0027/50, training time: 0.8s, inference time: 0.0s
train loss: 23102466.1758, val_loss: 134723664.0000
2022-09-26 19:47:46 | epoch: 0028/50, training time: 0.8s, inference time: 0.1s
train loss: 17689057.8901, val_loss: 129367576.0000
2022-09-26 19:47:46 | epoch: 0029/50, training time: 0.8s, inference time: 0.0s
train loss: 16928253.2637, val_loss: 122078424.0000
2022-09-26 19:47:47 | epoch: 0030/50, training time: 0.8s, inference time: 0.0s
train loss: 17810099.4725, val_loss: 133142848.0000
2022-09-26 19:47:48 | epoch: 0031/50, training time: 0.7s, inference time: 0.0s
train loss: 14431314.7692, val_loss: 164912672.0000
2022-09-26 19:47:49 | epoch: 0032/50, training time: 0.7s, inference time: 0.0s
train loss: 13561347.3407, val_loss: 129524272.0000
2022-09-26 19:47:49 | epoch: 0033/50, training time: 0.7s, inference time: 0.0s
train loss: 18741314.3626, val_loss: 132417712.0000
2022-09-26 19:47:50 | epoch: 0034/50, training time: 0.7s, inference time: 0.0s
train loss: 16751840.7912, val_loss: 145550480.0000
2022-09-26 19:47:51 | epoch: 0035/50, training time: 0.8s, inference time: 0.0s
train loss: 20845995.3407, val_loss: 128531368.0000
2022-09-26 19:47:52 | epoch: 0036/50, training time: 0.8s, inference time: 0.0s
train loss: 25379165.6593, val_loss: 142905792.0000
2022-09-26 19:47:53 | epoch: 0037/50, training time: 0.8s, inference time: 0.0s
train loss: 16590569.7363, val_loss: 140528544.0000
2022-09-26 19:47:53 | epoch: 0038/50, training time: 0.8s, inference time: 0.0s
train loss: 16514277.4066, val_loss: 133947696.0000
2022-09-26 19:47:54 | epoch: 0039/50, training time: 0.7s, inference time: 0.0s
train loss: 14470213.8462, val_loss: 132508496.0000
2022-09-26 19:47:55 | epoch: 0040/50, training time: 0.8s, inference time: 0.0s
train loss: 17475132.8571, val_loss: 134495760.0000
2022-09-26 19:47:56 | epoch: 0041/50, training time: 0.8s, inference time: 0.0s
train loss: 12854990.0000, val_loss: 132270248.0000
2022-09-26 19:47:57 | epoch: 0042/50, training time: 0.8s, inference time: 0.0s
train loss: 15038017.5824, val_loss: 133558760.0000
2022-09-26 19:47:57 | epoch: 0043/50, training time: 0.8s, inference time: 0.0s
train loss: 11070255.1758, val_loss: 131484848.0000
2022-09-26 19:47:58 | epoch: 0044/50, training time: 0.8s, inference time: 0.0s
train loss: 11340687.5714, val_loss: 133977576.0000
2022-09-26 19:47:59 | epoch: 0045/50, training time: 0.5s, inference time: 0.0s
train loss: 17684737.1429, val_loss: 118867824.0000
2022-09-26 19:47:59 | epoch: 0046/50, training time: 0.5s, inference time: 0.0s
train loss: 9268113.3516, val_loss: 123298960.0000
2022-09-26 19:48:00 | epoch: 0047/50, training time: 0.4s, inference time: 0.0s
train loss: 9434964.8571, val_loss: 133347736.0000
2022-09-26 19:48:00 | epoch: 0048/50, training time: 0.5s, inference time: 0.0s
train loss: 12363818.4725, val_loss: 127414680.0000
2022-09-26 19:48:01 | epoch: 0049/50, training time: 0.4s, inference time: 0.0s
train loss: 13700676.3516, val_loss: 118518384.0000
2022-09-26 19:48:01 | epoch: 0050/50, training time: 0.4s, inference time: 0.0s
train loss: 6876419.4066, val_loss: 136367232.0000
Training and validation are completed, and model has been stored as ./output/test-hyper-parameter(price)/learning_rate/0.01/model.pkl
**** testing model ****
loading model from ./output/test-hyper-parameter(price)/learning_rate/0.01/model.pkl
model restored!
evaluating...
testing time: 0.0s
                MAE		RMSE		MAPE
train            1869.22		2394.92		3.68%
val              9041.60		11677.64		16.46%
test             9610.10		11437.07		15.98%
performance in each prediction step
step: 01         9610.10		11437.07		15.98%
average:         9610.10		11437.07		15.98%
total time: 0.6min
