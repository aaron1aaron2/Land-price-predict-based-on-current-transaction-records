K=8, L=1, SE_file='./data/train_data/basic/SE_data/group0/SE.txt', batch_size=8, d=8, decay_epoch=10, device='cpu', learning_rate=0.001, log_file='./output/test-hyper-parameter(price)/batch_size/8/log.txt', max_epoch=50, model_file='./output/test-hyper-parameter(price)/batch_size/8/model.pkl', num_his=3, num_pred=1, output_folder='./output/test-hyper-parameter(price)/batch_size/8/', patience=100, test_ratio=0.1, time_slot=1440, traffic_file='./data/train_data/basic/train_data/mean_group0_dist3000.h5', train_ratio=0.8, val_ratio=0.1, view_batch_freq=100
main output folder./output/test-hyper-parameter(price)/batch_size/8
loading data...
trainX: torch.Size([91, 3, 5])		 trainY: torch.Size([91, 1, 5])
valX:   torch.Size([8, 3, 5])		valY:   torch.Size([8, 1, 5])
testX:   torch.Size([9, 3, 5])		testY:   torch.Size([9, 1, 5])
data loaded!
compiling model...
trainable parameters: 209,923
**** training model ****
2022-09-26 19:45:35 | epoch: 0001/50, training time: 1.0s, inference time: 0.0s
train loss: 198727444.5714, val_loss: 161024912.0000
val loss decrease from inf to 161024912.0000, saving model to ./output/test-hyper-parameter(price)/batch_size/8/model.pkl
2022-09-26 19:45:36 | epoch: 0002/50, training time: 1.2s, inference time: 0.0s
train loss: 128134457.6703, val_loss: 144054624.0000
val loss decrease from 161024912.0000 to 144054624.0000, saving model to ./output/test-hyper-parameter(price)/batch_size/8/model.pkl
2022-09-26 19:45:37 | epoch: 0003/50, training time: 1.0s, inference time: 0.0s
train loss: 114403410.2857, val_loss: 123283032.0000
val loss decrease from 144054624.0000 to 123283032.0000, saving model to ./output/test-hyper-parameter(price)/batch_size/8/model.pkl
2022-09-26 19:45:38 | epoch: 0004/50, training time: 0.9s, inference time: 0.0s
train loss: 101620178.9890, val_loss: 103238472.0000
val loss decrease from 123283032.0000 to 103238472.0000, saving model to ./output/test-hyper-parameter(price)/batch_size/8/model.pkl
2022-09-26 19:45:39 | epoch: 0005/50, training time: 1.0s, inference time: 0.0s
train loss: 101559738.7253, val_loss: 100145120.0000
val loss decrease from 103238472.0000 to 100145120.0000, saving model to ./output/test-hyper-parameter(price)/batch_size/8/model.pkl
2022-09-26 19:45:40 | epoch: 0006/50, training time: 0.7s, inference time: 0.0s
train loss: 94558068.2198, val_loss: 124137360.0000
2022-09-26 19:45:41 | epoch: 0007/50, training time: 0.8s, inference time: 0.0s
train loss: 82968061.1868, val_loss: 130095824.0000
2022-09-26 19:45:42 | epoch: 0008/50, training time: 0.8s, inference time: 0.0s
train loss: 87468841.8462, val_loss: 150659008.0000
2022-09-26 19:45:42 | epoch: 0009/50, training time: 0.7s, inference time: 0.0s
train loss: 72483605.9341, val_loss: 188633984.0000
2022-09-26 19:45:43 | epoch: 0010/50, training time: 0.7s, inference time: 0.0s
train loss: 83320368.0000, val_loss: 193784160.0000
2022-09-26 19:45:44 | epoch: 0011/50, training time: 0.7s, inference time: 0.0s
train loss: 74560730.8132, val_loss: 131817168.0000
2022-09-26 19:45:44 | epoch: 0012/50, training time: 0.7s, inference time: 0.0s
train loss: 69453369.7582, val_loss: 117174888.0000
2022-09-26 19:45:45 | epoch: 0013/50, training time: 0.7s, inference time: 0.0s
train loss: 64226345.7582, val_loss: 154806368.0000
2022-09-26 19:45:46 | epoch: 0014/50, training time: 0.8s, inference time: 0.0s
train loss: 59742636.7912, val_loss: 148677648.0000
2022-09-26 19:45:47 | epoch: 0015/50, training time: 0.8s, inference time: 0.0s
train loss: 55218522.6374, val_loss: 157659104.0000
2022-09-26 19:45:47 | epoch: 0016/50, training time: 0.7s, inference time: 0.0s
train loss: 64357465.6264, val_loss: 183421152.0000
2022-09-26 19:45:48 | epoch: 0017/50, training time: 0.7s, inference time: 0.0s
train loss: 55910148.4835, val_loss: 145986896.0000
2022-09-26 19:45:49 | epoch: 0018/50, training time: 0.7s, inference time: 0.0s
train loss: 63643610.0220, val_loss: 158464512.0000
2022-09-26 19:45:49 | epoch: 0019/50, training time: 0.7s, inference time: 0.0s
train loss: 58238056.1538, val_loss: 145286864.0000
2022-09-26 19:45:50 | epoch: 0020/50, training time: 0.7s, inference time: 0.0s
train loss: 52626643.6044, val_loss: 153818400.0000
2022-09-26 19:45:51 | epoch: 0021/50, training time: 0.7s, inference time: 0.0s
train loss: 55997340.3956, val_loss: 173705696.0000
2022-09-26 19:45:52 | epoch: 0022/50, training time: 0.8s, inference time: 0.0s
train loss: 50695678.4176, val_loss: 163772000.0000
2022-09-26 19:45:52 | epoch: 0023/50, training time: 0.7s, inference time: 0.0s
train loss: 53501022.3297, val_loss: 152132176.0000
2022-09-26 19:45:53 | epoch: 0024/50, training time: 0.7s, inference time: 0.0s
train loss: 49512220.3516, val_loss: 176519728.0000
2022-09-26 19:45:54 | epoch: 0025/50, training time: 0.7s, inference time: 0.0s
train loss: 46471382.3736, val_loss: 183264528.0000
2022-09-26 19:45:55 | epoch: 0026/50, training time: 0.7s, inference time: 0.0s
train loss: 54472893.1868, val_loss: 174481792.0000
2022-09-26 19:45:55 | epoch: 0027/50, training time: 0.7s, inference time: 0.0s
train loss: 44568521.3187, val_loss: 151408448.0000
2022-09-26 19:45:56 | epoch: 0028/50, training time: 0.7s, inference time: 0.0s
train loss: 43311649.5824, val_loss: 162208384.0000
2022-09-26 19:45:57 | epoch: 0029/50, training time: 0.8s, inference time: 0.0s
train loss: 46230549.8022, val_loss: 176147776.0000
2022-09-26 19:45:58 | epoch: 0030/50, training time: 0.7s, inference time: 0.0s
train loss: 45761250.4615, val_loss: 165540288.0000
2022-09-26 19:45:58 | epoch: 0031/50, training time: 0.7s, inference time: 0.0s
train loss: 45317975.8681, val_loss: 145140000.0000
2022-09-26 19:45:59 | epoch: 0032/50, training time: 0.7s, inference time: 0.0s
train loss: 49971683.6923, val_loss: 159829552.0000
2022-09-26 19:46:00 | epoch: 0033/50, training time: 0.7s, inference time: 0.0s
train loss: 44673574.0659, val_loss: 176734464.0000
2022-09-26 19:46:00 | epoch: 0034/50, training time: 0.7s, inference time: 0.0s
train loss: 42967867.6923, val_loss: 175293264.0000
2022-09-26 19:46:01 | epoch: 0035/50, training time: 0.7s, inference time: 0.0s
train loss: 46413122.7692, val_loss: 147826432.0000
2022-09-26 19:46:02 | epoch: 0036/50, training time: 0.8s, inference time: 0.0s
train loss: 37147043.2967, val_loss: 159604448.0000
2022-09-26 19:46:03 | epoch: 0037/50, training time: 0.7s, inference time: 0.0s
train loss: 40941536.3516, val_loss: 151876240.0000
2022-09-26 19:46:04 | epoch: 0038/50, training time: 0.7s, inference time: 0.0s
train loss: 37864260.4396, val_loss: 157384400.0000
2022-09-26 19:46:04 | epoch: 0039/50, training time: 0.7s, inference time: 0.0s
train loss: 38230217.8462, val_loss: 140282272.0000
2022-09-26 19:46:05 | epoch: 0040/50, training time: 0.7s, inference time: 0.0s
train loss: 38798614.6154, val_loss: 134131600.0000
2022-09-26 19:46:06 | epoch: 0041/50, training time: 0.7s, inference time: 0.0s
train loss: 34463260.3956, val_loss: 129810344.0000
2022-09-26 19:46:06 | epoch: 0042/50, training time: 0.7s, inference time: 0.0s
train loss: 35999618.2857, val_loss: 156160352.0000
2022-09-26 19:46:07 | epoch: 0043/50, training time: 0.7s, inference time: 0.0s
train loss: 37640950.4176, val_loss: 149685920.0000
2022-09-26 19:46:08 | epoch: 0044/50, training time: 0.8s, inference time: 0.0s
train loss: 34972170.5495, val_loss: 163095232.0000
2022-09-26 19:46:09 | epoch: 0045/50, training time: 0.7s, inference time: 0.0s
train loss: 32557373.3626, val_loss: 160794272.0000
2022-09-26 19:46:09 | epoch: 0046/50, training time: 0.7s, inference time: 0.0s
train loss: 39525162.2857, val_loss: 174393568.0000
2022-09-26 19:46:10 | epoch: 0047/50, training time: 0.7s, inference time: 0.0s
train loss: 34847243.3407, val_loss: 163461456.0000
2022-09-26 19:46:11 | epoch: 0048/50, training time: 0.7s, inference time: 0.0s
train loss: 32646420.1758, val_loss: 154518304.0000
2022-09-26 19:46:12 | epoch: 0049/50, training time: 0.7s, inference time: 0.0s
train loss: 34210258.9011, val_loss: 163402240.0000
2022-09-26 19:46:12 | epoch: 0050/50, training time: 0.8s, inference time: 0.0s
train loss: 29503090.7253, val_loss: 157734240.0000
Training and validation are completed, and model has been stored as ./output/test-hyper-parameter(price)/batch_size/8/model.pkl
**** testing model ****
loading model from ./output/test-hyper-parameter(price)/batch_size/8/model.pkl
model restored!
evaluating...
testing time: 0.0s
                MAE		RMSE		MAPE
train            3629.53		4664.59		6.88%
val              9253.17		12559.23		16.00%
test             9794.35		11785.64		16.71%
performance in each prediction step
step: 01         9794.35		11785.64		16.71%
average:         9794.35		11785.64		16.71%
total time: 0.7min
