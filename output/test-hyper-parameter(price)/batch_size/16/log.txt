K=8, L=1, SE_file='./data/train_data/basic/SE_data/group0/SE.txt', batch_size=16, d=8, decay_epoch=10, device='cpu', learning_rate=0.001, log_file='./output/test-hyper-parameter(price)/batch_size/16/log.txt', max_epoch=50, model_file='./output/test-hyper-parameter(price)/batch_size/16/model.pkl', num_his=3, num_pred=1, output_folder='./output/test-hyper-parameter(price)/batch_size/16/', patience=100, test_ratio=0.1, time_slot=1440, traffic_file='./data/train_data/basic/train_data/mean_group0_dist3000.h5', train_ratio=0.8, val_ratio=0.1, view_batch_freq=100
main output folder./output/test-hyper-parameter(price)/batch_size/16
loading data...
trainX: torch.Size([91, 3, 5])		 trainY: torch.Size([91, 1, 5])
valX:   torch.Size([8, 3, 5])		valY:   torch.Size([8, 1, 5])
testX:   torch.Size([9, 3, 5])		testY:   torch.Size([9, 1, 5])
data loaded!
compiling model...
trainable parameters: 209,923
**** training model ****
2022-09-26 19:46:19 | epoch: 0001/50, training time: 0.5s, inference time: 0.0s
train loss: 217820760.5275, val_loss: 167593632.0000
val loss decrease from inf to 167593632.0000, saving model to ./output/test-hyper-parameter(price)/batch_size/16/model.pkl
2022-09-26 19:46:19 | epoch: 0002/50, training time: 0.6s, inference time: 0.0s
train loss: 122992810.9011, val_loss: 162337888.0000
val loss decrease from 167593632.0000 to 162337888.0000, saving model to ./output/test-hyper-parameter(price)/batch_size/16/model.pkl
2022-09-26 19:46:20 | epoch: 0003/50, training time: 0.6s, inference time: 0.0s
train loss: 99028057.3187, val_loss: 156335952.0000
val loss decrease from 162337888.0000 to 156335952.0000, saving model to ./output/test-hyper-parameter(price)/batch_size/16/model.pkl
2022-09-26 19:46:21 | epoch: 0004/50, training time: 0.6s, inference time: 0.0s
train loss: 88748770.6813, val_loss: 146746368.0000
val loss decrease from 156335952.0000 to 146746368.0000, saving model to ./output/test-hyper-parameter(price)/batch_size/16/model.pkl
2022-09-26 19:46:21 | epoch: 0005/50, training time: 0.6s, inference time: 0.0s
train loss: 85797202.1978, val_loss: 144430752.0000
val loss decrease from 146746368.0000 to 144430752.0000, saving model to ./output/test-hyper-parameter(price)/batch_size/16/model.pkl
2022-09-26 19:46:22 | epoch: 0006/50, training time: 0.5s, inference time: 0.0s
train loss: 75818787.4286, val_loss: 144035088.0000
val loss decrease from 144430752.0000 to 144035088.0000, saving model to ./output/test-hyper-parameter(price)/batch_size/16/model.pkl
2022-09-26 19:46:23 | epoch: 0007/50, training time: 0.6s, inference time: 0.0s
train loss: 70364735.4725, val_loss: 165802384.0000
2022-09-26 19:46:23 | epoch: 0008/50, training time: 0.6s, inference time: 0.0s
train loss: 58591343.2088, val_loss: 169792784.0000
2022-09-26 19:46:24 | epoch: 0009/50, training time: 0.6s, inference time: 0.0s
train loss: 60804436.4835, val_loss: 161944896.0000
2022-09-26 19:46:24 | epoch: 0010/50, training time: 0.5s, inference time: 0.0s
train loss: 50986648.7912, val_loss: 150389968.0000
2022-09-26 19:46:25 | epoch: 0011/50, training time: 0.4s, inference time: 0.0s
train loss: 42867651.6044, val_loss: 151819440.0000
2022-09-26 19:46:25 | epoch: 0012/50, training time: 0.4s, inference time: 0.0s
train loss: 42798022.1978, val_loss: 158479824.0000
2022-09-26 19:46:26 | epoch: 0013/50, training time: 0.5s, inference time: 0.0s
train loss: 41072033.5385, val_loss: 155936976.0000
2022-09-26 19:46:26 | epoch: 0014/50, training time: 0.4s, inference time: 0.0s
train loss: 40041035.4725, val_loss: 146880640.0000
2022-09-26 19:46:27 | epoch: 0015/50, training time: 0.4s, inference time: 0.0s
train loss: 34968450.9451, val_loss: 161215392.0000
2022-09-26 19:46:27 | epoch: 0016/50, training time: 0.4s, inference time: 0.0s
train loss: 37188677.0549, val_loss: 180253104.0000
2022-09-26 19:46:27 | epoch: 0017/50, training time: 0.4s, inference time: 0.0s
train loss: 33912133.0549, val_loss: 178403104.0000
2022-09-26 19:46:28 | epoch: 0018/50, training time: 0.4s, inference time: 0.0s
train loss: 34893550.7692, val_loss: 168250848.0000
2022-09-26 19:46:28 | epoch: 0019/50, training time: 0.4s, inference time: 0.0s
train loss: 37069697.6703, val_loss: 164145408.0000
2022-09-26 19:46:29 | epoch: 0020/50, training time: 0.5s, inference time: 0.0s
train loss: 31369290.8352, val_loss: 175469600.0000
2022-09-26 19:46:29 | epoch: 0021/50, training time: 0.5s, inference time: 0.0s
train loss: 31575676.4835, val_loss: 172246064.0000
2022-09-26 19:46:30 | epoch: 0022/50, training time: 0.4s, inference time: 0.0s
train loss: 27962323.7363, val_loss: 178318944.0000
2022-09-26 19:46:30 | epoch: 0023/50, training time: 0.4s, inference time: 0.0s
train loss: 26485263.9121, val_loss: 171177696.0000
2022-09-26 19:46:31 | epoch: 0024/50, training time: 0.4s, inference time: 0.0s
train loss: 27129749.5385, val_loss: 160113088.0000
2022-09-26 19:46:31 | epoch: 0025/50, training time: 0.4s, inference time: 0.0s
train loss: 26186625.6703, val_loss: 166696256.0000
2022-09-26 19:46:31 | epoch: 0026/50, training time: 0.4s, inference time: 0.0s
train loss: 28577455.2308, val_loss: 170337760.0000
2022-09-26 19:46:32 | epoch: 0027/50, training time: 0.4s, inference time: 0.0s
train loss: 27111199.2967, val_loss: 166213904.0000
2022-09-26 19:46:32 | epoch: 0028/50, training time: 0.4s, inference time: 0.0s
train loss: 20123522.1099, val_loss: 161688336.0000
2022-09-26 19:46:33 | epoch: 0029/50, training time: 0.4s, inference time: 0.0s
train loss: 21911995.5165, val_loss: 161874848.0000
2022-09-26 19:46:33 | epoch: 0030/50, training time: 0.4s, inference time: 0.0s
train loss: 19494958.6813, val_loss: 155566560.0000
2022-09-26 19:46:34 | epoch: 0031/50, training time: 0.4s, inference time: 0.0s
train loss: 25016614.9011, val_loss: 155694800.0000
2022-09-26 19:46:34 | epoch: 0032/50, training time: 0.4s, inference time: 0.0s
train loss: 23118331.6044, val_loss: 155341776.0000
2022-09-26 19:46:34 | epoch: 0033/50, training time: 0.4s, inference time: 0.0s
train loss: 22815409.9560, val_loss: 149884832.0000
2022-09-26 19:46:35 | epoch: 0034/50, training time: 0.4s, inference time: 0.0s
train loss: 21507651.4725, val_loss: 152310624.0000
2022-09-26 19:46:35 | epoch: 0035/50, training time: 0.4s, inference time: 0.0s
train loss: 17116459.4066, val_loss: 154979440.0000
2022-09-26 19:46:36 | epoch: 0036/50, training time: 0.5s, inference time: 0.0s
train loss: 27551993.4505, val_loss: 156509088.0000
2022-09-26 19:46:36 | epoch: 0037/50, training time: 0.5s, inference time: 0.0s
train loss: 20917300.7912, val_loss: 158134672.0000
2022-09-26 19:46:37 | epoch: 0038/50, training time: 0.5s, inference time: 0.0s
train loss: 20195314.0000, val_loss: 159058720.0000
2022-09-26 19:46:37 | epoch: 0039/50, training time: 0.4s, inference time: 0.0s
train loss: 19377794.2857, val_loss: 150061664.0000
2022-09-26 19:46:38 | epoch: 0040/50, training time: 0.4s, inference time: 0.0s
train loss: 20320785.6923, val_loss: 150189136.0000
2022-09-26 19:46:38 | epoch: 0041/50, training time: 0.5s, inference time: 0.0s
train loss: 18945411.0769, val_loss: 156341536.0000
2022-09-26 19:46:39 | epoch: 0042/50, training time: 0.4s, inference time: 0.0s
train loss: 16656358.4835, val_loss: 159638432.0000
2022-09-26 19:46:39 | epoch: 0043/50, training time: 0.4s, inference time: 0.0s
train loss: 17228494.0659, val_loss: 157915120.0000
2022-09-26 19:46:40 | epoch: 0044/50, training time: 0.4s, inference time: 0.0s
train loss: 16463303.7802, val_loss: 160690880.0000
2022-09-26 19:46:40 | epoch: 0045/50, training time: 0.4s, inference time: 0.0s
train loss: 21402105.9121, val_loss: 163635984.0000
2022-09-26 19:46:40 | epoch: 0046/50, training time: 0.4s, inference time: 0.0s
train loss: 15295466.4835, val_loss: 151325984.0000
2022-09-26 19:46:41 | epoch: 0047/50, training time: 0.4s, inference time: 0.0s
train loss: 16995240.0879, val_loss: 149974896.0000
2022-09-26 19:46:41 | epoch: 0048/50, training time: 0.4s, inference time: 0.0s
train loss: 18582516.3626, val_loss: 151427504.0000
2022-09-26 19:46:42 | epoch: 0049/50, training time: 0.4s, inference time: 0.0s
train loss: 18107503.0110, val_loss: 147484048.0000
2022-09-26 19:46:42 | epoch: 0050/50, training time: 0.4s, inference time: 0.0s
train loss: 14940847.4176, val_loss: 145896160.0000
Training and validation are completed, and model has been stored as ./output/test-hyper-parameter(price)/batch_size/16/model.pkl
**** testing model ****
loading model from ./output/test-hyper-parameter(price)/batch_size/16/model.pkl
model restored!
evaluating...
testing time: 0.0s
                MAE		RMSE		MAPE
train            3081.07		4016.15		6.25%
val              9238.46		12078.75		16.31%
test             9482.34		11407.41		16.05%
performance in each prediction step
step: 01         9482.34		11407.41		16.05%
average:         9482.34		11407.41		16.05%
total time: 0.4min
